{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the `TensorFlow` and `numpy` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our neural network to \"learn\" the relationship between list of inputs and list of outputs\n",
    "\n",
    "**Example**\n",
    "Here `x` represents the input array, which is a 2D array with 4 column (input) variables. `y` represents the output variable, which is 1D array with 1 output value per row in the `x` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 1.0, 4.5, 2.3, 6.7, 1.0], dtype=float)\n",
    "y = np.array([-3.0, -1.0, 1.0, 3.0, 4.0, 2.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>student</th>\n",
       "      <th>wfh_now</th>\n",
       "      <th>prod_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Increased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Decreased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Decreased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Decreased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes, Full-time</td>\n",
       "      <td>Yes</td>\n",
       "      <td>In some ways it has increased and in other way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>9319</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Question not displayed to respondent</td>\n",
       "      <td>Question not displayed to respondent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>9322</td>\n",
       "      <td>47</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Increased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>9323</td>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>About the same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>9325</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Decreased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>9337</td>\n",
       "      <td>71</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Question not displayed to respondent</td>\n",
       "      <td>Question not displayed to respondent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2905 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      resp_id  age  gender         student  \\\n",
       "0          11   44    Male              No   \n",
       "1          29   39    Male              No   \n",
       "2          30   49  Female              No   \n",
       "3          31   27    Male              No   \n",
       "4          34   32  Female  Yes, Full-time   \n",
       "...       ...  ...     ...             ...   \n",
       "2900     9319   67    Male              No   \n",
       "2901     9322   47  Female              No   \n",
       "2902     9323   59    Male              No   \n",
       "2903     9325   60  Female              No   \n",
       "2904     9337   71    Male              No   \n",
       "\n",
       "                                   wfh_now  \\\n",
       "0                                      Yes   \n",
       "1                                      Yes   \n",
       "2                                      Yes   \n",
       "3                                      Yes   \n",
       "4                                      Yes   \n",
       "...                                    ...   \n",
       "2900  Question not displayed to respondent   \n",
       "2901                                    No   \n",
       "2902                                    No   \n",
       "2903                                    No   \n",
       "2904  Question not displayed to respondent   \n",
       "\n",
       "                                            prod_change  \n",
       "0                                    Increased somewhat  \n",
       "1                                    Decreased somewhat  \n",
       "2                                    Decreased somewhat  \n",
       "3                                    Decreased somewhat  \n",
       "4     In some ways it has increased and in other way...  \n",
       "...                                                 ...  \n",
       "2900               Question not displayed to respondent  \n",
       "2901                                 Increased somewhat  \n",
       "2902                                     About the same  \n",
       "2903                                 Decreased somewhat  \n",
       "2904               Question not displayed to respondent  \n",
       "\n",
       "[2905 rows x 6 columns]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data = data.loc[:,['resp_id', 'age', 'gender', 'student', 'wfh_now', 'prod_change']]\n",
    "data.columns = data.columns.to_series().apply(lambda x: x.strip())\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up data\n",
    "\n",
    "We now have to convert the data from text to decimal values, to provide consistency over all the columns which will help the model fit our data.\n",
    "\n",
    "Gender: 0 Male, 1 Female\n",
    "\n",
    "Student: 0 Not a student, 1 Student Full time, 2 Student Part time\n",
    "\n",
    "WFH_Now: 0 No, 1 Yes\n",
    "\n",
    "Prod_Change: 0 Decreased Significantly, 1 Decreased Somewhat, 2 Both, 3 Same, 4 Increased somewhat, 5 Increased significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>student</th>\n",
       "      <th>wfh_now</th>\n",
       "      <th>prod_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>9280</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>9281</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>9286</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>9322</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>9325</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      resp_id  age gender student wfh_now prod_change\n",
       "0          11   44      0       0       1           4\n",
       "1          29   39      0       0       1           1\n",
       "2          30   49      1       0       1           1\n",
       "3          31   27      0       0       1           1\n",
       "10         46   63      1       0       1           4\n",
       "...       ...  ...    ...     ...     ...         ...\n",
       "2887     9280   61      1       0       1           4\n",
       "2888     9281   65      1       0       1           4\n",
       "2890     9286   67      0       0       1           4\n",
       "2901     9322   47      1       0       0           4\n",
       "2903     9325   60      1       0       0           1\n",
       "\n",
       "[616 rows x 6 columns]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genders = {\n",
    "  'Male' : 0,\n",
    "  'Female' : 1,\n",
    "}\n",
    "\n",
    "Student = {\n",
    "  'No' : 0,\n",
    "  'Yes' : 1,\n",
    "}\n",
    "\n",
    "WFH_Now = {\n",
    "  'No' : 0,\n",
    "  'Yes' : 1,\n",
    "}\n",
    "\n",
    "Prod_Change = {\n",
    "  'Decreased significantly': 0,\n",
    "  'Decreased somewhat': 1,\n",
    "  'Both': 2,\n",
    "  'Same': 3,\n",
    "  'Increased somewhat': 4,\n",
    "  'Increased significantly': 5,\n",
    "}\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "  # print(index)\n",
    "  gender = row['gender']\n",
    "  student = row['student']\n",
    "  wfh_now = row['wfh_now']\n",
    "  prod_change = row['prod_change']\n",
    "\n",
    "  data.loc[index, 'gender'] = Genders.get(gender, -1)\n",
    "  data.loc[index, 'student'] = Student.get(student, -1)\n",
    "  data.loc[index, 'wfh_now'] = WFH_Now.get(wfh_now, -1)\n",
    "  data.loc[index, 'prod_change'] = Prod_Change.get(prod_change, -1)\n",
    "  \n",
    "  # drop all the rows that have missing values (aka have a -1 in any column)\n",
    "  if (data.loc[index, 'gender'] == -1 or data.loc[index, 'student']==-1 or data.loc[index, 'wfh_now']==-1 or data.loc[index, 'prod_change']==-1):\n",
    "    data.drop(labels=index, axis=0, inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the simplest possible neural network. It has 1 layer, that layer has 1 neuron, and the input is just 1 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_162 (Dense)           (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compile the neural network by specifying a **loss function** and an **optimization algorithm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now **train** our neural network to fit the data. The neural network will try to guess the relationship between the values in `x` and the values in `y`. The loss function will measure how good or how bad this guess is and, based on this, the optimization algorithm will make another guess. We then repeat this process for a certin number of iterations (`epochs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 0s 512us/step - loss: 7.9241\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 480us/step - loss: 4.8005\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 447us/step - loss: 3.7649\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 425us/step - loss: 3.4463\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 437us/step - loss: 3.3299\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 377us/step - loss: 3.2808\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 421us/step - loss: 3.2594\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 413us/step - loss: 3.2480\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 383us/step - loss: 3.2391\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 417us/step - loss: 3.2338\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 419us/step - loss: 3.2267\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 422us/step - loss: 3.2184\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 410us/step - loss: 3.2135\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 413us/step - loss: 3.2091\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 402us/step - loss: 3.2062\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 421us/step - loss: 3.2025\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 413us/step - loss: 3.2019\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 392us/step - loss: 3.1993\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 409us/step - loss: 3.1972\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 387us/step - loss: 3.1964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e9e360d0>"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.loc[:,['gender']]\n",
    "y = data.loc[:,['prod_change']]\n",
    "\n",
    "x = np.asarray(x).astype('float32')\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "model.fit(x, y, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test our neural network by using it to predict the value of `prod_change` for a previously unseen value of `gender` (for example, `gender=1`). **What do you think the value of `prod_change` will be?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[2.346479 ]\n",
      " [2.3014915]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([1.0,0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reasonable prediction since we only used binary gender as input and productivity levels (0-5) as output. And we currently assume no correlation between the two categories but we will improve our model but adding more features and improving the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "* The most challenging part of this project is estimating individual productivity since there are many factors that could affect human behvaior, it's hard to draw conclusion, and it's also hard to use all the features from our survey data to simply predict productivity.\n",
    "* Our initial insights is that workplace productivity is affected when people change scenes and switch between working in person to working from home. And the choice to work from home is fueled by other factors including education, income, job type, etc. \n",
    "* We don't have concrete results yet because we cleaned up the data and found out we might not have enough data of a certain feature to use it in the final model. We will have to tweak the model significantly.\n",
    "* Biggest problems currently facing: Tweaking the neural network, training data and minimizing loss.\n",
    "* We are on track to completing the project on time.\n",
    "* Yes it's worth proceeding with the project because we have enough diverse set of features to draw important conclusions affecting individual's (and families) work from home productivity in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wave 1 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_id</th>\n",
       "      <th>WFH_PRE</th>\n",
       "      <th>Job_Clerical or administrative support</th>\n",
       "      <th>Job_Manufacturing, construction, maintenance, or farming</th>\n",
       "      <th>Job_Professional, managerial, or technical</th>\n",
       "      <th>Job_Sales or service</th>\n",
       "      <th>Workload_increased</th>\n",
       "      <th>Workload_decreased</th>\n",
       "      <th>Increased_productivity</th>\n",
       "      <th>Decreased_productivity</th>\n",
       "      <th>hhveh_harm</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Number_bedrooms</th>\n",
       "      <th>Race_white</th>\n",
       "      <th>Gradutae_degree</th>\n",
       "      <th>High_income(LessThan_100K)</th>\n",
       "      <th>More_income(LMoreThan_35K)</th>\n",
       "      <th>ProEnvironment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>3714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>3730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>3733</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>3738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     resp_id  WFH_PRE  Job_Clerical or administrative support  \\\n",
       "0         11        0                                       0   \n",
       "1         29        1                                       0   \n",
       "2         30        0                                       0   \n",
       "3         31        1                                       0   \n",
       "4         34        1                                       0   \n",
       "..       ...      ...                                     ...   \n",
       "816     3710        1                                       0   \n",
       "817     3714        0                                       1   \n",
       "818     3730        0                                       0   \n",
       "819     3733        1                                       0   \n",
       "820     3738        1                                       1   \n",
       "\n",
       "     Job_Manufacturing, construction, maintenance, or farming  \\\n",
       "0                                                    0          \n",
       "1                                                    0          \n",
       "2                                                    0          \n",
       "3                                                    0          \n",
       "4                                                    0          \n",
       "..                                                 ...          \n",
       "816                                                  0          \n",
       "817                                                  0          \n",
       "818                                                  1          \n",
       "819                                                  0          \n",
       "820                                                  0          \n",
       "\n",
       "     Job_Professional, managerial, or technical  Job_Sales or service  \\\n",
       "0                                             0                     0   \n",
       "1                                             1                     0   \n",
       "2                                             1                     0   \n",
       "3                                             1                     0   \n",
       "4                                             1                     0   \n",
       "..                                          ...                   ...   \n",
       "816                                           0                     1   \n",
       "817                                           0                     0   \n",
       "818                                           0                     0   \n",
       "819                                           1                     0   \n",
       "820                                           0                     0   \n",
       "\n",
       "     Workload_increased  Workload_decreased  Increased_productivity  \\\n",
       "0                     1                   0                       1   \n",
       "1                     0                   0                       0   \n",
       "2                     0                   0                       0   \n",
       "3                     0                   0                       0   \n",
       "4                     0                   1                       0   \n",
       "..                  ...                 ...                     ...   \n",
       "816                   0                   0                       0   \n",
       "817                   0                   0                       0   \n",
       "818                   0                   1                       0   \n",
       "819                   0                   0                       0   \n",
       "820                   1                   0                       1   \n",
       "\n",
       "     Decreased_productivity  hhveh_harm  age  gender  Number_bedrooms  \\\n",
       "0                         0           2   44       1                5   \n",
       "1                         1           1   39       1                2   \n",
       "2                         1           4   49       0                4   \n",
       "3                         1           1   27       1                1   \n",
       "4                         0           0   32       0                5   \n",
       "..                      ...         ...  ...     ...              ...   \n",
       "816                       0           2   63       1                4   \n",
       "817                       0           1   62       1                3   \n",
       "818                       1           2   57       1                2   \n",
       "819                       0           2   34       0                3   \n",
       "820                       0           1   70       0                3   \n",
       "\n",
       "     Race_white  Gradutae_degree  High_income(LessThan_100K)  \\\n",
       "0             1                0                           0   \n",
       "1             1                1                           0   \n",
       "2             1                0                           0   \n",
       "3             1                1                           0   \n",
       "4             0                0                           0   \n",
       "..          ...              ...                         ...   \n",
       "816           1                1                           0   \n",
       "817           1                0                           0   \n",
       "818           1                0                           0   \n",
       "819           1                1                           0   \n",
       "820           1                0                           1   \n",
       "\n",
       "     More_income(LMoreThan_35K)  ProEnvironment  \n",
       "0                             0               1  \n",
       "1                             1               1  \n",
       "2                             1               1  \n",
       "3                             1               1  \n",
       "4                             0               1  \n",
       "..                          ...             ...  \n",
       "816                           1               1  \n",
       "817                           0               1  \n",
       "818                           0               1  \n",
       "819                           1               0  \n",
       "820                           0               1  \n",
       "\n",
       "[821 rows x 19 columns]"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave1 = pd.read_csv(\"Wave1_train.csv\")      # All Data\n",
    "\n",
    "train = wave1.iloc[:821,:]            # Training Data\n",
    "validation = wave1.iloc[821:,:]       # Validation Data\n",
    "\n",
    "test = pd.read_csv(\"Wave1_test.csv\")  # Test Data\n",
    "train.columns = train.columns.to_series().apply(lambda x: x.strip())\n",
    "train.shape, validation.shape\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the simplest possible neural network. It has 1 layer, that layer has 1 neuron, and the input is just 1 value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Job Type Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_68\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_332 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_333 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_334 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_335 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_336 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_68 (Concatenate)   (None, 5)            0           ['input_332[0][0]',              \n",
      "                                                                  'input_333[0][0]',              \n",
      "                                                                  'input_334[0][0]',              \n",
      "                                                                  'input_335[0][0]',              \n",
      "                                                                  'input_336[0][0]']              \n",
      "                                                                                                  \n",
      " dense_163 (Dense)              (None, 5)            30          ['concatenate_68[0][0]']         \n",
      "                                                                                                  \n",
      " dense_164 (Dense)              (None, 1)            6           ['dense_163[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "w1_input1 = tf.keras.layers.Input(shape=(1,))\n",
    "w1_input2 = tf.keras.layers.Input(shape=(1,))\n",
    "w1_input3 = tf.keras.layers.Input(shape=(1,))\n",
    "w1_input4 = tf.keras.layers.Input(shape=(1,))\n",
    "w1_input5 = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([w1_input1, w1_input2, w1_input3, w1_input4, w1_input5])\n",
    "dense1 = tf.keras.layers.Dense(5, input_dim=1, activation=tf.keras.activations.sigmoid, use_bias=True)(merged)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.keras.activations.relu, use_bias=True)(dense1)\n",
    "age_job_category_model = tf.keras.models.Model([w1_input1, w1_input2, w1_input3, w1_input4, w1_input5], output)\n",
    "age_job_category_model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "age_job_category_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2771 - accuracy: 0.4762 - val_loss: 0.2595 - val_accuracy: 0.4251\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.4836 - val_loss: 0.2482 - val_accuracy: 0.5713\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.4580 - val_loss: 0.2536 - val_accuracy: 0.4811\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.4823 - val_loss: 0.2462 - val_accuracy: 0.5956\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.4750 - val_loss: 0.2682 - val_accuracy: 0.3898\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.4580 - val_loss: 0.2688 - val_accuracy: 0.3934\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.4738 - val_loss: 0.2532 - val_accuracy: 0.4482\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.4848 - val_loss: 0.2613 - val_accuracy: 0.3983\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.4799 - val_loss: 0.2556 - val_accuracy: 0.4032\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.4555 - val_loss: 0.2597 - val_accuracy: 0.3959\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.4519 - val_loss: 0.2488 - val_accuracy: 0.5591\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.4799 - val_loss: 0.2576 - val_accuracy: 0.4056\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.4750 - val_loss: 0.2543 - val_accuracy: 0.4604\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.4519 - val_loss: 0.2504 - val_accuracy: 0.4896\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.4629 - val_loss: 0.2559 - val_accuracy: 0.3971\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.4641 - val_loss: 0.2519 - val_accuracy: 0.4629\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.4762 - val_loss: 0.2505 - val_accuracy: 0.4714\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.4665 - val_loss: 0.2494 - val_accuracy: 0.4884\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2513 - accuracy: 0.5055 - val_loss: 0.2502 - val_accuracy: 0.4775\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.4531 - val_loss: 0.2498 - val_accuracy: 0.4714\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.4653 - val_loss: 0.2494 - val_accuracy: 0.4994\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4823 - val_loss: 0.2493 - val_accuracy: 0.5055\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.4860 - val_loss: 0.2483 - val_accuracy: 0.6017\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.5067 - val_loss: 0.2489 - val_accuracy: 0.6005\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4811 - val_loss: 0.2477 - val_accuracy: 0.6029\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4933 - val_loss: 0.2479 - val_accuracy: 0.6017\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.5091 - val_loss: 0.2487 - val_accuracy: 0.6005\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.4994 - val_loss: 0.2478 - val_accuracy: 0.6017\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.5104 - val_loss: 0.2483 - val_accuracy: 0.6017\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.5091 - val_loss: 0.2486 - val_accuracy: 0.5993\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.4823 - val_loss: 0.2479 - val_accuracy: 0.6017\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5091 - val_loss: 0.2484 - val_accuracy: 0.6017\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4945 - val_loss: 0.2483 - val_accuracy: 0.6017\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5079 - val_loss: 0.2487 - val_accuracy: 0.5993\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5006 - val_loss: 0.2481 - val_accuracy: 0.6017\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5091 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.5104 - val_loss: 0.2489 - val_accuracy: 0.6005\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4909 - val_loss: 0.2483 - val_accuracy: 0.6017\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.5104 - val_loss: 0.2488 - val_accuracy: 0.5993\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.5030 - val_loss: 0.2485 - val_accuracy: 0.6017\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.5055 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5091 - val_loss: 0.2484 - val_accuracy: 0.6017\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5067 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4884 - val_loss: 0.2470 - val_accuracy: 0.6029\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5079 - val_loss: 0.2469 - val_accuracy: 0.6029\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5091 - val_loss: 0.2477 - val_accuracy: 0.6029\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5006 - val_loss: 0.2470 - val_accuracy: 0.6029\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5091 - val_loss: 0.2466 - val_accuracy: 0.6029\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5104 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.5104 - val_loss: 0.2486 - val_accuracy: 0.6017\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.4921 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5091 - val_loss: 0.2480 - val_accuracy: 0.6029\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5104 - val_loss: 0.2483 - val_accuracy: 0.6029\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.5055 - val_loss: 0.2480 - val_accuracy: 0.6029\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5091 - val_loss: 0.2484 - val_accuracy: 0.6017\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5091 - val_loss: 0.2496 - val_accuracy: 0.6029\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4872 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5067 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5104 - val_loss: 0.2485 - val_accuracy: 0.6017\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.4896 - val_loss: 0.2467 - val_accuracy: 0.6029\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5018 - val_loss: 0.2466 - val_accuracy: 0.6029\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4872 - val_loss: 0.2463 - val_accuracy: 0.6029\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.5091 - val_loss: 0.2475 - val_accuracy: 0.6029\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2474 - val_accuracy: 0.6029\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2480 - val_accuracy: 0.6029\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5006 - val_loss: 0.2477 - val_accuracy: 0.6029\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2485 - val_accuracy: 0.6029\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5006 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5043 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5091 - val_loss: 0.2473 - val_accuracy: 0.6029\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.5104 - val_loss: 0.2474 - val_accuracy: 0.6029\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5104 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5104 - val_loss: 0.2487 - val_accuracy: 0.6029\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5079 - val_loss: 0.2480 - val_accuracy: 0.6029\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.4811 - val_loss: 0.2470 - val_accuracy: 0.6029\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.5116 - val_loss: 0.2480 - val_accuracy: 0.6029\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2487 - val_accuracy: 0.6029\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.4945 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2489 - val_accuracy: 0.6029\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4823 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.5043 - val_loss: 0.2477 - val_accuracy: 0.6029\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.5104 - val_loss: 0.2473 - val_accuracy: 0.6029\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2480 - val_accuracy: 0.6029\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5006 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5006 - val_loss: 0.2474 - val_accuracy: 0.6029\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5104 - val_loss: 0.2477 - val_accuracy: 0.6029\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5055 - val_loss: 0.2477 - val_accuracy: 0.6029\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5104 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.5116 - val_loss: 0.2486 - val_accuracy: 0.6029\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.5006 - val_loss: 0.2483 - val_accuracy: 0.6029\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2483 - val_accuracy: 0.6029\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.4982 - val_loss: 0.2473 - val_accuracy: 0.6029\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.5116 - val_loss: 0.2471 - val_accuracy: 0.6029\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.5079 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2481 - val_accuracy: 0.6029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e662bf10>"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data\n",
    "w1_input1 = train.loc[:,['age']]\n",
    "w1_input2 = train.loc[:,['Job_Clerical or administrative support']]\n",
    "w1_input3 = train.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "w1_input4 = train.loc[:,['Job_Professional, managerial, or technical']]\n",
    "w1_input5 = train.loc[:,['Job_Sales or service']]\n",
    "\n",
    "w1_input1 = np.asarray(w1_input1).astype('float32')\n",
    "w1_input2 = np.asarray(w1_input2).astype('float32')\n",
    "w1_input3 = np.asarray(w1_input3).astype('float32')\n",
    "w1_input4 = np.asarray(w1_input4).astype('float32')\n",
    "w1_input5 = np.asarray(w1_input5).astype('float32')\n",
    "\n",
    "w1_y = train.loc[:,['WFH_PRE']]\n",
    "w1_y = np.asarray(w1_y).astype('float32')\n",
    "\n",
    "# Validation data\n",
    "v_w1_input1 = validation.loc[:,['age']]\n",
    "v_w1_input2 = validation.loc[:,['Job_Clerical or administrative support']]\n",
    "v_w1_input3 = validation.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "v_w1_input4 = validation.loc[:,['Job_Professional, managerial, or technical']]\n",
    "v_w1_input5 = validation.loc[:,['Job_Sales or service']]\n",
    "\n",
    "v_w1_input1 = np.asarray(v_w1_input1).astype('float32')\n",
    "v_w1_input2 = np.asarray(v_w1_input2).astype('float32')\n",
    "v_w1_input3 = np.asarray(v_w1_input3).astype('float32')\n",
    "v_w1_input4 = np.asarray(v_w1_input4).astype('float32')\n",
    "v_w1_input5 = np.asarray(v_w1_input5).astype('float32')\n",
    "\n",
    "v_w1_y = validation.loc[:,['WFH_PRE']]\n",
    "v_w1_y = np.asarray(v_w1_y).astype('float32')\n",
    "\n",
    "age_job_category_model.fit([w1_input1, w1_input2, w1_input3, w1_input4, w1_input5],w1_y, \n",
    "                        batch_size=36, epochs=100, validation_data=([v_w1_input1, v_w1_input2, v_w1_input3, v_w1_input4, v_w1_input5], v_w1_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "t_w1_input1 = test.loc[:,['age']]\n",
    "t_w1_input2 = test.loc[:,['Job_Clerical or administrative support']]\n",
    "t_w1_input3 = test.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "t_w1_input4 = test.loc[:,['Job_Professional, managerial, or technical']]\n",
    "t_w1_input5 = test.loc[:,['Job_Sales or service']]\n",
    "\n",
    "t_w1_input1 = np.asarray(t_w1_input1).astype('float32')\n",
    "t_w1_input2 = np.asarray(t_w1_input2).astype('float32')\n",
    "t_w1_input3 = np.asarray(t_w1_input3).astype('float32')\n",
    "t_w1_input4 = np.asarray(t_w1_input4).astype('float32')\n",
    "t_w1_input5 = np.asarray(t_w1_input5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 485us/step\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "age_job_categroy_wave1 = age_job_category_model.predict([t_w1_input1, t_w1_input2, t_w1_input3, t_w1_input4, t_w1_input5])\n",
    "# age_job_category_model.predict([t_w1_input1, t_w1_input2, t_w1_input3, t_w1_input4, t_w1_input5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree or Pro Environment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_69\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_337 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_338 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_339 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_340 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_341 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_69 (Concatenate)   (None, 5)            0           ['input_337[0][0]',              \n",
      "                                                                  'input_338[0][0]',              \n",
      "                                                                  'input_339[0][0]',              \n",
      "                                                                  'input_340[0][0]',              \n",
      "                                                                  'input_341[0][0]']              \n",
      "                                                                                                  \n",
      " dense_165 (Dense)              (None, 5)            30          ['concatenate_69[0][0]']         \n",
      "                                                                                                  \n",
      " dense_166 (Dense)              (None, 1)            6           ['dense_165[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(1,))\n",
    "input2 = tf.keras.layers.Input(shape=(1,))\n",
    "input3 = tf.keras.layers.Input(shape=(1,))\n",
    "input4 = tf.keras.layers.Input(shape=(1,))\n",
    "input5 = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([input1, input2, input3, input4, input5])\n",
    "dense1 = tf.keras.layers.Dense(5, input_dim=1, activation=tf.keras.activations.sigmoid, use_bias=True)(merged)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.keras.activations.relu, use_bias=True)(dense1)\n",
    "degree_environment_model = tf.keras.models.Model([input1, input2, input3, input4, input5], output)\n",
    "degree_environment_model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
    "degree_environment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2556 - accuracy: 0.5079 - val_loss: 0.2505 - val_accuracy: 0.4568\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.4762 - val_loss: 0.2496 - val_accuracy: 0.4519\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.4982 - val_loss: 0.2510 - val_accuracy: 0.4373\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.4653 - val_loss: 0.2485 - val_accuracy: 0.6029\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.4762 - val_loss: 0.2507 - val_accuracy: 0.4348\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4799 - val_loss: 0.2445 - val_accuracy: 0.6029\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5067 - val_loss: 0.2514 - val_accuracy: 0.4300\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4848 - val_loss: 0.2492 - val_accuracy: 0.4677\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.4641 - val_loss: 0.2465 - val_accuracy: 0.6029\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.5104 - val_loss: 0.2465 - val_accuracy: 0.6029\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4957 - val_loss: 0.2455 - val_accuracy: 0.6029\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5079 - val_loss: 0.2483 - val_accuracy: 0.6029\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5104 - val_loss: 0.2517 - val_accuracy: 0.4300\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.4945 - val_loss: 0.2475 - val_accuracy: 0.6029\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5164 - val_loss: 0.2461 - val_accuracy: 0.6029\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2508 - val_accuracy: 0.4336\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.5006 - val_loss: 0.2507 - val_accuracy: 0.4336\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5018 - val_loss: 0.2458 - val_accuracy: 0.6029\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2488 - val_accuracy: 0.6029\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2522 - val_accuracy: 0.4251\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4982 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.4933 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.4957 - val_loss: 0.2442 - val_accuracy: 0.6029\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.4970 - val_loss: 0.2467 - val_accuracy: 0.6029\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.5018 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.4787 - val_loss: 0.2461 - val_accuracy: 0.6029\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.5189 - val_loss: 0.2522 - val_accuracy: 0.4141\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.4823 - val_loss: 0.2494 - val_accuracy: 0.5737\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.4957 - val_loss: 0.2456 - val_accuracy: 0.6029\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5006 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.4848 - val_loss: 0.2443 - val_accuracy: 0.6029\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.4970 - val_loss: 0.2450 - val_accuracy: 0.6029\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4970 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.5006 - val_loss: 0.2487 - val_accuracy: 0.6029\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4970 - val_loss: 0.2493 - val_accuracy: 0.6029\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5043 - val_loss: 0.2499 - val_accuracy: 0.4409\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4994 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4872 - val_loss: 0.2461 - val_accuracy: 0.6029\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4909 - val_loss: 0.2455 - val_accuracy: 0.6029\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.5116 - val_loss: 0.2492 - val_accuracy: 0.6029\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4982 - val_loss: 0.2462 - val_accuracy: 0.6029\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.4896 - val_loss: 0.2474 - val_accuracy: 0.6029\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4787 - val_loss: 0.2466 - val_accuracy: 0.6029\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.4811 - val_loss: 0.2466 - val_accuracy: 0.6029\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4970 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.5104 - val_loss: 0.2458 - val_accuracy: 0.6029\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4811 - val_loss: 0.2456 - val_accuracy: 0.6029\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.4970 - val_loss: 0.2468 - val_accuracy: 0.6029\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5055 - val_loss: 0.2474 - val_accuracy: 0.6029\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.5055 - val_loss: 0.2451 - val_accuracy: 0.6029\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.5116 - val_loss: 0.2489 - val_accuracy: 0.6029\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.4933 - val_loss: 0.2450 - val_accuracy: 0.6029\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4884 - val_loss: 0.2457 - val_accuracy: 0.6029\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.5116 - val_loss: 0.2473 - val_accuracy: 0.6029\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.5006 - val_loss: 0.2502 - val_accuracy: 0.4397\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.4811 - val_loss: 0.2497 - val_accuracy: 0.4568\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.5091 - val_loss: 0.2490 - val_accuracy: 0.6029\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.4750 - val_loss: 0.2461 - val_accuracy: 0.6029\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.4702 - val_loss: 0.2471 - val_accuracy: 0.6029\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4836 - val_loss: 0.2464 - val_accuracy: 0.6029\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5079 - val_loss: 0.2471 - val_accuracy: 0.6029\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.4994 - val_loss: 0.2483 - val_accuracy: 0.6029\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.4994 - val_loss: 0.2507 - val_accuracy: 0.4324\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4775 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4823 - val_loss: 0.2455 - val_accuracy: 0.6029\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.5213 - val_loss: 0.2555 - val_accuracy: 0.3995\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.4592 - val_loss: 0.2518 - val_accuracy: 0.4068\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.4811 - val_loss: 0.2521 - val_accuracy: 0.4068\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4543 - val_loss: 0.2459 - val_accuracy: 0.6029\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.4982 - val_loss: 0.2490 - val_accuracy: 0.6029\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4909 - val_loss: 0.2485 - val_accuracy: 0.6029\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.4970 - val_loss: 0.2492 - val_accuracy: 0.6029\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.5079 - val_loss: 0.2498 - val_accuracy: 0.4470\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.4884 - val_loss: 0.2469 - val_accuracy: 0.6029\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4970 - val_loss: 0.2453 - val_accuracy: 0.6029\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.5091 - val_loss: 0.2510 - val_accuracy: 0.4300\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.5067 - val_loss: 0.2505 - val_accuracy: 0.4336\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.4860 - val_loss: 0.2470 - val_accuracy: 0.6029\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.5067 - val_loss: 0.2468 - val_accuracy: 0.6029\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5006 - val_loss: 0.2491 - val_accuracy: 0.6029\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5043 - val_loss: 0.2482 - val_accuracy: 0.6029\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.5116 - val_loss: 0.2491 - val_accuracy: 0.6029\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5018 - val_loss: 0.2465 - val_accuracy: 0.6029\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.5116 - val_loss: 0.2533 - val_accuracy: 0.4032\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.4811 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.4957 - val_loss: 0.2491 - val_accuracy: 0.6029\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.4799 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.5104 - val_loss: 0.2469 - val_accuracy: 0.6029\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4921 - val_loss: 0.2474 - val_accuracy: 0.6029\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.5006 - val_loss: 0.2488 - val_accuracy: 0.6029\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.5006 - val_loss: 0.2492 - val_accuracy: 0.6029\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5018 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5043 - val_loss: 0.2460 - val_accuracy: 0.6029\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5043 - val_loss: 0.2488 - val_accuracy: 0.6029\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.5067 - val_loss: 0.2505 - val_accuracy: 0.4336\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5067 - val_loss: 0.2440 - val_accuracy: 0.6029\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.4933 - val_loss: 0.2462 - val_accuracy: 0.6029\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.5055 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4957 - val_loss: 0.2469 - val_accuracy: 0.6029\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4896 - val_loss: 0.2473 - val_accuracy: 0.6029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d13ace80>"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data\n",
    "input1 = train.loc[:,['age']]\n",
    "input2 = train.loc[:,['Workload_increased']]\n",
    "input3 = train.loc[:,['Workload_decreased']]\n",
    "input4 = train.loc[:,['Gradutae_degree']]\n",
    "input5 = train.loc[:,['ProEnvironment']]\n",
    "\n",
    "input1 = np.asarray(input1).astype('float32')\n",
    "input2 = np.asarray(input2).astype('float32')\n",
    "input3 = np.asarray(input3).astype('float32')\n",
    "input4 = np.asarray(input4).astype('float32')\n",
    "input5 = np.asarray(input5).astype('float32')\n",
    "\n",
    "y = train.loc[:,['WFH_PRE']]\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "# Validation Data\n",
    "v_input1 = validation.loc[:,['age']]\n",
    "v_input2 = validation.loc[:,['Workload_increased']]\n",
    "v_input3 = validation.loc[:,['Workload_decreased']]\n",
    "v_input4 = validation.loc[:,['Gradutae_degree']]\n",
    "v_input5 = validation.loc[:,['ProEnvironment']]\n",
    "\n",
    "v_input1 = np.asarray(v_input1).astype('float32')\n",
    "v_input2 = np.asarray(v_input2).astype('float32')\n",
    "v_input3 = np.asarray(v_input3).astype('float32')\n",
    "v_input4 = np.asarray(v_input4).astype('float32')\n",
    "v_input5 = np.asarray(v_input5).astype('float32')\n",
    "\n",
    "v_y = validation.loc[:,['WFH_PRE']]\n",
    "v_y = np.asarray(v_y).astype('float32')\n",
    "\n",
    "degree_environment_model.fit([input1, input2, input3, input4, input5],y, batch_size=36, epochs=100, \n",
    "                        validation_data=([v_input1, v_input2, v_input3, v_input4, v_input5], v_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "t2_input1 = test.loc[:,['age']]\n",
    "t2_input2 = test.loc[:,['Workload_increased']]\n",
    "t2_input3 = test.loc[:,['Workload_decreased']]\n",
    "t2_input4 = test.loc[:,['Gradutae_degree']]\n",
    "t2_input5 = test.loc[:,['ProEnvironment']]\n",
    "\n",
    "t2_input1 = np.asarray(t2_input1).astype('float32')\n",
    "t2_input2 = np.asarray(t2_input2).astype('float32')\n",
    "t2_input3 = np.asarray(t2_input3).astype('float32')\n",
    "t2_input4 = np.asarray(t2_input4).astype('float32')\n",
    "t2_input5 = np.asarray(t2_input5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 519us/step\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "degree_environment_wave1 = degree_environment_model.predict([t2_input1, t2_input2, t2_input3, t2_input4, t2_input5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wave 2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_id</th>\n",
       "      <th>wfh_expect</th>\n",
       "      <th>Job_Clerical or administrative support</th>\n",
       "      <th>Job_Manufacturing, construction, maintenance, or farming</th>\n",
       "      <th>Job_Professional, managerial, or technical</th>\n",
       "      <th>Job_Sales or service</th>\n",
       "      <th>Workload_increased</th>\n",
       "      <th>Workload_decreased</th>\n",
       "      <th>Increased_productivity</th>\n",
       "      <th>Decreased_productivity</th>\n",
       "      <th>hhveh_harm</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Number_bedrooms</th>\n",
       "      <th>Race_white</th>\n",
       "      <th>Gradutae_degree</th>\n",
       "      <th>High_income(LessThan_100K)</th>\n",
       "      <th>More_income(LMoreThan_35K)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1177</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>4593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>4601</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>4613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>4618</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>4622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>684 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     resp_id wfh_expect  Job_Clerical or administrative support  \\\n",
       "0       1177          1                                       0   \n",
       "1       1188          1                                       0   \n",
       "2       1189          1                                       0   \n",
       "3       1194          1                                       0   \n",
       "4       1202          1                                       0   \n",
       "..       ...        ...                                     ...   \n",
       "679     4593          0                                       0   \n",
       "680     4601          1                                       0   \n",
       "681     4613          1                                       0   \n",
       "682     4618          1                                       0   \n",
       "683     4622          0                                       0   \n",
       "\n",
       "     Job_Manufacturing, construction, maintenance, or farming  \\\n",
       "0                                                    0          \n",
       "1                                                    0          \n",
       "2                                                    0          \n",
       "3                                                    0          \n",
       "4                                                    0          \n",
       "..                                                 ...          \n",
       "679                                                  0          \n",
       "680                                                  0          \n",
       "681                                                  0          \n",
       "682                                                  0          \n",
       "683                                                  0          \n",
       "\n",
       "     Job_Professional, managerial, or technical  Job_Sales or service  \\\n",
       "0                                             1                     0   \n",
       "1                                             1                     0   \n",
       "2                                             0                     0   \n",
       "3                                             1                     0   \n",
       "4                                             0                     0   \n",
       "..                                          ...                   ...   \n",
       "679                                           0                     1   \n",
       "680                                           1                     0   \n",
       "681                                           0                     1   \n",
       "682                                           1                     0   \n",
       "683                                           0                     0   \n",
       "\n",
       "     Workload_increased  Workload_decreased  Increased_productivity  \\\n",
       "0                     0                   0                       1   \n",
       "1                     0                   0                       1   \n",
       "2                     0                   0                       0   \n",
       "3                     0                   0                       0   \n",
       "4                     0                   0                       0   \n",
       "..                  ...                 ...                     ...   \n",
       "679                   0                   1                       0   \n",
       "680                   0                   0                       0   \n",
       "681                   1                   0                       1   \n",
       "682                   0                   1                       0   \n",
       "683                   0                   0                       0   \n",
       "\n",
       "     Decreased_productivity  hhveh_harm  age  gender  Number_bedrooms  \\\n",
       "0                         0           2   58       1                3   \n",
       "1                         0           1   66       0                2   \n",
       "2                         0           0   24       1                3   \n",
       "3                         0           1   31       1                3   \n",
       "4                         0           0   23       0                2   \n",
       "..                      ...         ...  ...     ...              ...   \n",
       "679                       1           4   59       0                3   \n",
       "680                       0           2   56       1                3   \n",
       "681                       0           2   66       0                4   \n",
       "682                       1           1   73       0                3   \n",
       "683                       0           2   53       1                3   \n",
       "\n",
       "     Race_white  Gradutae_degree  High_income(LessThan_100K)  \\\n",
       "0             0                1                           0   \n",
       "1             1                0                           0   \n",
       "2             1                0                           1   \n",
       "3             1                1                           0   \n",
       "4             0                1                           1   \n",
       "..          ...              ...                         ...   \n",
       "679           1                0                           0   \n",
       "680           1                0                           0   \n",
       "681           1                1                           0   \n",
       "682           1                1                           0   \n",
       "683           1                0                           1   \n",
       "\n",
       "     More_income(LMoreThan_35K)  \n",
       "0                             1  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             1  \n",
       "4                             0  \n",
       "..                          ...  \n",
       "679                           1  \n",
       "680                           0  \n",
       "681                           1  \n",
       "682                           0  \n",
       "683                           0  \n",
       "\n",
       "[684 rows x 18 columns]"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave2 = pd.read_csv(\"Wave2_train.csv\")      # All Data\n",
    "\n",
    "WFH_EXPECT = {\n",
    "  'No' : 0,\n",
    "  'Yes' : 1,\n",
    "}\n",
    "\n",
    "for index, row in wave2.iterrows():\n",
    "  # print(index)\n",
    "  wfh_expect = row['wfh_expect']\n",
    "\n",
    "  wave2.loc[index, 'wfh_expect'] = WFH_EXPECT.get(wfh_expect, -1)\n",
    "\n",
    "\n",
    "train = wave2.iloc[:684,:]                  # Training Data\n",
    "validation = wave2.iloc[684:,:]             # Validation Data\n",
    "\n",
    "test = pd.read_csv(\"Wave2_test.csv\")        # Test Data\n",
    "train.columns = train.columns.to_series().apply(lambda x: x.strip())\n",
    "train.shape, validation.shape\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the simplest possible neural network. It has 1 layer, that layer has 1 neuron, and the input is just 1 value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Job Type Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_72\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_351 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_352 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_353 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_354 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_355 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_72 (Concatenate)   (None, 5)            0           ['input_351[0][0]',              \n",
      "                                                                  'input_352[0][0]',              \n",
      "                                                                  'input_353[0][0]',              \n",
      "                                                                  'input_354[0][0]',              \n",
      "                                                                  'input_355[0][0]']              \n",
      "                                                                                                  \n",
      " dense_171 (Dense)              (None, 5)            30          ['concatenate_72[0][0]']         \n",
      "                                                                                                  \n",
      " dense_172 (Dense)              (None, 1)            6           ['dense_171[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(1,))\n",
    "input2 = tf.keras.layers.Input(shape=(1,))\n",
    "input3 = tf.keras.layers.Input(shape=(1,))\n",
    "input4 = tf.keras.layers.Input(shape=(1,))\n",
    "input5 = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([input1, input2, input3, input4, input5])\n",
    "dense1 = tf.keras.layers.Dense(5, input_dim=1, activation=tf.keras.activations.sigmoid, use_bias=True)(merged)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.keras.activations.relu, use_bias=True)(dense1)\n",
    "age_job_category_model_wave2 = tf.keras.models.Model([input1, input2, input3, input4, input5], output)\n",
    "age_job_category_model_wave2.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
    "age_job_category_model_wave2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2756 - accuracy: 0.5015 - val_loss: 0.2567 - val_accuracy: 0.5029\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.5015 - val_loss: 0.2510 - val_accuracy: 0.5029\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.5015 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4781 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.4956 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4751 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5015 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4956 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4985 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4927 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4868 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4810 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4868 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4971 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4810 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4985 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4664 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4927 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4810 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5044 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4751 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4927 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4985 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4985 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5015 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5073 - val_loss: 0.2501 - val_accuracy: 0.5029\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.4810 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5190 - val_loss: 0.2502 - val_accuracy: 0.4971\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4868 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.5132 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4781 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4722 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4751 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5073 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4810 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4810 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5044 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4868 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4722 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4956 - val_loss: 0.2500 - val_accuracy: 0.4927\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4956 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5015 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4883 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4912 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4985 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4985 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4664 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4810 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5015 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4927 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4518 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4722 - val_loss: 0.2500 - val_accuracy: 0.5015\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4781 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4532 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4839 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4956 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4942 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4927 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4868 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4781 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4693 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4985 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4985 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4868 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4722 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4664 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4912 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5073 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4781 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4868 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4985 - val_loss: 0.2502 - val_accuracy: 0.4971\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4781 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4751 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4927 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4985 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4810 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5102 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4883 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4927 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5029 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4898 - val_loss: 0.2501 - val_accuracy: 0.4971\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4868 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4956 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4722 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4561 - val_loss: 0.2500 - val_accuracy: 0.5029\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4956 - val_loss: 0.2500 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4985 - val_loss: 0.2500 - val_accuracy: 0.5029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dd1b0dc0>"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data\n",
    "input1 = train.loc[:,['age']]\n",
    "input2 = train.loc[:,['Job_Clerical or administrative support']]\n",
    "input3 = train.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "input4 = train.loc[:,['Job_Professional, managerial, or technical']]\n",
    "input5 = train.loc[:,['Job_Sales or service']]\n",
    "\n",
    "input1 = np.asarray(input1).astype('float32')\n",
    "input2 = np.asarray(input2).astype('float32')\n",
    "input3 = np.asarray(input3).astype('float32')\n",
    "input4 = np.asarray(input4).astype('float32')\n",
    "input5 = np.asarray(input5).astype('float32')\n",
    "\n",
    "y = train.loc[:,['wfh_expect']]\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "# Validation data\n",
    "v_input1 = validation.loc[:,['age']]\n",
    "v_input2 = validation.loc[:,['Job_Clerical or administrative support']]\n",
    "v_input3 = validation.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "v_input4 = validation.loc[:,['Job_Professional, managerial, or technical']]\n",
    "v_input5 = validation.loc[:,['Job_Sales or service']]\n",
    "\n",
    "v_input1 = np.asarray(v_input1).astype('float32')\n",
    "v_input2 = np.asarray(v_input2).astype('float32')\n",
    "v_input3 = np.asarray(v_input3).astype('float32')\n",
    "v_input4 = np.asarray(v_input4).astype('float32')\n",
    "v_input5 = np.asarray(v_input5).astype('float32')\n",
    "\n",
    "v_y = validation.loc[:,['wfh_expect']]\n",
    "v_y = np.asarray(v_y).astype('float32')\n",
    "\n",
    "age_job_category_model_wave2.fit([input1, input2, input3, input4, input5],y, \n",
    "                        batch_size=36, epochs=100, validation_data=([v_input1, v_input2, v_input3, v_input4, v_input5], v_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "t_input1 = test.loc[:,['age']]\n",
    "t_input2 = test.loc[:,['Job_Clerical or administrative support']]\n",
    "t_input3 = test.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "t_input4 = test.loc[:,['Job_Professional, managerial, or technical']]\n",
    "t_input5 = test.loc[:,['Job_Sales or service']]\n",
    "\n",
    "t_input1 = np.asarray(t_input1).astype('float32')\n",
    "t_input2 = np.asarray(t_input2).astype('float32')\n",
    "t_input3 = np.asarray(t_input3).astype('float32')\n",
    "t_input4 = np.asarray(t_input4).astype('float32')\n",
    "t_input5 = np.asarray(t_input5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 544us/step\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "age_job_categroy_wave2 = age_job_category_model_wave2.predict([t_input1, t_input2, t_input3, t_input4, t_input5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree or Pro Environment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_73\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_356 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_357 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_358 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_359 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_73 (Concatenate)   (None, 4)            0           ['input_356[0][0]',              \n",
      "                                                                  'input_357[0][0]',              \n",
      "                                                                  'input_358[0][0]',              \n",
      "                                                                  'input_359[0][0]']              \n",
      "                                                                                                  \n",
      " dense_173 (Dense)              (None, 4)            20          ['concatenate_73[0][0]']         \n",
      "                                                                                                  \n",
      " dense_174 (Dense)              (None, 1)            5           ['dense_173[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(1,))\n",
    "input2 = tf.keras.layers.Input(shape=(1,))\n",
    "input3 = tf.keras.layers.Input(shape=(1,))\n",
    "input4 = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([input1, input2, input3, input4])\n",
    "dense1 = tf.keras.layers.Dense(4, input_dim=1, activation=tf.keras.activations.sigmoid, use_bias=True)(merged)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.keras.activations.relu, use_bias=True)(dense1)\n",
    "degree_environment_model_wave2 = tf.keras.models.Model([input1, input2, input3, input4], output)\n",
    "degree_environment_model_wave2.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
    "degree_environment_model_wave2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2617 - accuracy: 0.5015 - val_loss: 0.2521 - val_accuracy: 0.5029\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.5015 - val_loss: 0.2498 - val_accuracy: 0.5029\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.4898 - val_loss: 0.2495 - val_accuracy: 0.5029\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.5058 - val_loss: 0.2495 - val_accuracy: 0.5029\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.4693 - val_loss: 0.2495 - val_accuracy: 0.5029\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.5132 - val_loss: 0.2495 - val_accuracy: 0.5365\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.5102 - val_loss: 0.2496 - val_accuracy: 0.5234\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.5000 - val_loss: 0.2496 - val_accuracy: 0.5219\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4956 - val_loss: 0.2496 - val_accuracy: 0.5234\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4839 - val_loss: 0.2496 - val_accuracy: 0.5292\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4708 - val_loss: 0.2496 - val_accuracy: 0.5439\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4737 - val_loss: 0.2496 - val_accuracy: 0.5351\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4971 - val_loss: 0.2497 - val_accuracy: 0.5073\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4635 - val_loss: 0.2497 - val_accuracy: 0.5132\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4839 - val_loss: 0.2497 - val_accuracy: 0.5190\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4971 - val_loss: 0.2497 - val_accuracy: 0.5132\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4635 - val_loss: 0.2497 - val_accuracy: 0.5263\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4518 - val_loss: 0.2497 - val_accuracy: 0.5439\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4722 - val_loss: 0.2497 - val_accuracy: 0.5029\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4693 - val_loss: 0.2497 - val_accuracy: 0.5205\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4810 - val_loss: 0.2498 - val_accuracy: 0.5029\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4810 - val_loss: 0.2498 - val_accuracy: 0.5029\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5015 - val_loss: 0.2498 - val_accuracy: 0.5190\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.5058 - val_loss: 0.2498 - val_accuracy: 0.4883\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.5044 - val_loss: 0.2498 - val_accuracy: 0.5132\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.4854 - val_loss: 0.2498 - val_accuracy: 0.4942\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4708 - val_loss: 0.2498 - val_accuracy: 0.4912\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.4708 - val_loss: 0.2498 - val_accuracy: 0.4956\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4942 - val_loss: 0.2498 - val_accuracy: 0.4971\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5000 - val_loss: 0.2499 - val_accuracy: 0.5132\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4737 - val_loss: 0.2498 - val_accuracy: 0.4766\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4868 - val_loss: 0.2499 - val_accuracy: 0.5073\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4561 - val_loss: 0.2499 - val_accuracy: 0.5249\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4971 - val_loss: 0.2499 - val_accuracy: 0.5088\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4751 - val_loss: 0.2499 - val_accuracy: 0.5234\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.4635 - val_loss: 0.2499 - val_accuracy: 0.5015\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4825 - val_loss: 0.2499 - val_accuracy: 0.5102\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4781 - val_loss: 0.2499 - val_accuracy: 0.5175\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4839 - val_loss: 0.2499 - val_accuracy: 0.4781\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4868 - val_loss: 0.2499 - val_accuracy: 0.4854\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4795 - val_loss: 0.2499 - val_accuracy: 0.4956\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4722 - val_loss: 0.2499 - val_accuracy: 0.4898\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4708 - val_loss: 0.2499 - val_accuracy: 0.4781\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4985 - val_loss: 0.2499 - val_accuracy: 0.4971\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4649 - val_loss: 0.2499 - val_accuracy: 0.4956\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4605 - val_loss: 0.2499 - val_accuracy: 0.4898\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4942 - val_loss: 0.2499 - val_accuracy: 0.5044\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.4942 - val_loss: 0.2499 - val_accuracy: 0.4942\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4854 - val_loss: 0.2499 - val_accuracy: 0.4927\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4444 - val_loss: 0.2499 - val_accuracy: 0.4927\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5015 - val_loss: 0.2500 - val_accuracy: 0.4825\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5029 - val_loss: 0.2500 - val_accuracy: 0.5044\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.4781\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4825 - val_loss: 0.2500 - val_accuracy: 0.4781\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4883 - val_loss: 0.2500 - val_accuracy: 0.5088\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.4737\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4649 - val_loss: 0.2500 - val_accuracy: 0.5073\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4883 - val_loss: 0.2500 - val_accuracy: 0.4795\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4912 - val_loss: 0.2500 - val_accuracy: 0.5073\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4708 - val_loss: 0.2500 - val_accuracy: 0.4883\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.4678\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4912 - val_loss: 0.2500 - val_accuracy: 0.4693\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.4839\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.4825 - val_loss: 0.2500 - val_accuracy: 0.4781\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.5058 - val_loss: 0.2500 - val_accuracy: 0.5058\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.4737 - val_loss: 0.2500 - val_accuracy: 0.4927\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4781 - val_loss: 0.2500 - val_accuracy: 0.5088\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4635 - val_loss: 0.2500 - val_accuracy: 0.5058\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5044 - val_loss: 0.2500 - val_accuracy: 0.4854\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5029 - val_loss: 0.2501 - val_accuracy: 0.4985\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4751 - val_loss: 0.2500 - val_accuracy: 0.4795\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4737 - val_loss: 0.2500 - val_accuracy: 0.4649\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4561 - val_loss: 0.2500 - val_accuracy: 0.4898\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4722 - val_loss: 0.2500 - val_accuracy: 0.5015\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4839 - val_loss: 0.2500 - val_accuracy: 0.5015\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5029 - val_loss: 0.2500 - val_accuracy: 0.4664\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4459 - val_loss: 0.2500 - val_accuracy: 0.4883\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5015 - val_loss: 0.2501 - val_accuracy: 0.5015\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4985 - val_loss: 0.2500 - val_accuracy: 0.5058\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5044 - val_loss: 0.2500 - val_accuracy: 0.5058\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4942 - val_loss: 0.2501 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4708 - val_loss: 0.2501 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4751 - val_loss: 0.2500 - val_accuracy: 0.4649\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4810 - val_loss: 0.2500 - val_accuracy: 0.5015\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5044 - val_loss: 0.2500 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.5015\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4956 - val_loss: 0.2500 - val_accuracy: 0.5073\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5044 - val_loss: 0.2500 - val_accuracy: 0.4971\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4898 - val_loss: 0.2500 - val_accuracy: 0.4912\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4708 - val_loss: 0.2500 - val_accuracy: 0.4825\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4898 - val_loss: 0.2501 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4839 - val_loss: 0.2501 - val_accuracy: 0.4956\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4635 - val_loss: 0.2501 - val_accuracy: 0.5015\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.4781 - val_loss: 0.2501 - val_accuracy: 0.4547\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4971 - val_loss: 0.2501 - val_accuracy: 0.4956\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4591 - val_loss: 0.2501 - val_accuracy: 0.4605\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4868 - val_loss: 0.2501 - val_accuracy: 0.5029\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4664 - val_loss: 0.2501 - val_accuracy: 0.5073\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4971 - val_loss: 0.2501 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4708 - val_loss: 0.2501 - val_accuracy: 0.4781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e826e250>"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data\n",
    "input1 = train.loc[:,['age']]\n",
    "input2 = train.loc[:,['Workload_increased']]\n",
    "input3 = train.loc[:,['Workload_decreased']]\n",
    "input4 = train.loc[:,['Gradutae_degree']]\n",
    "\n",
    "input1 = np.asarray(input1).astype('float32')\n",
    "input2 = np.asarray(input2).astype('float32')\n",
    "input3 = np.asarray(input3).astype('float32')\n",
    "input4 = np.asarray(input4).astype('float32')\n",
    "\n",
    "y = train.loc[:,['wfh_expect']]\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "# Validation Data\n",
    "v_input1 = validation.loc[:,['age']]\n",
    "v_input2 = validation.loc[:,['Workload_increased']]\n",
    "v_input3 = validation.loc[:,['Workload_decreased']]\n",
    "v_input4 = validation.loc[:,['Gradutae_degree']]\n",
    "\n",
    "v_input1 = np.asarray(v_input1).astype('float32')\n",
    "v_input2 = np.asarray(v_input2).astype('float32')\n",
    "v_input3 = np.asarray(v_input3).astype('float32')\n",
    "v_input4 = np.asarray(v_input4).astype('float32')\n",
    "\n",
    "v_y = validation.loc[:,['wfh_expect']]\n",
    "v_y = np.asarray(v_y).astype('float32')\n",
    "\n",
    "degree_environment_model_wave2.fit([input1, input2, input3, input4],y, batch_size=36, epochs=100, \n",
    "                        validation_data=([v_input1, v_input2, v_input3, v_input4], v_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "t_input1 = test.loc[:,['age']]\n",
    "t_input2 = test.loc[:,['Workload_increased']]\n",
    "t_input3 = test.loc[:,['Workload_decreased']]\n",
    "t_input4 = test.loc[:,['Gradutae_degree']]\n",
    "\n",
    "t_input1 = np.asarray(t_input1).astype('float32')\n",
    "t_input2 = np.asarray(t_input2).astype('float32')\n",
    "t_input3 = np.asarray(t_input3).astype('float32')\n",
    "t_input4 = np.asarray(t_input4).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 666us/step\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "degree_environment_wave2 = degree_environment_model_wave2.predict([t_input1, t_input2, t_input3, t_input4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the numpy arrays for the results of the prediction, it's only wave 1 for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49045208],\n",
       "       [0.4901969 ],\n",
       "       [0.4909247 ],\n",
       "       [0.486573  ],\n",
       "       [0.4887146 ],\n",
       "       [0.4901969 ],\n",
       "       [0.4846168 ],\n",
       "       [0.4910452 ],\n",
       "       [0.49113742],\n",
       "       [0.49107912],\n",
       "       [0.49103054],\n",
       "       [0.49107912],\n",
       "       [0.4909601 ],\n",
       "       [0.4911473 ],\n",
       "       [0.49009648],\n",
       "       [0.4909247 ],\n",
       "       [0.4857212 ],\n",
       "       [0.48935583],\n",
       "       [0.4911591 ],\n",
       "       [0.49113742],\n",
       "       [0.49103054],\n",
       "       [0.48950985],\n",
       "       [0.4909247 ],\n",
       "       [0.49089178],\n",
       "       [0.49109134],\n",
       "       [0.49110195],\n",
       "       [0.4887146 ],\n",
       "       [0.48837855],\n",
       "       [0.49004564],\n",
       "       [0.49100932],\n",
       "       [0.48776665],\n",
       "       [0.4901969 ],\n",
       "       [0.4910651 ],\n",
       "       [0.4911112 ],\n",
       "       [0.4900566 ],\n",
       "       [0.4909247 ],\n",
       "       [0.49115488],\n",
       "       [0.49088785],\n",
       "       [0.48862258],\n",
       "       [0.49060574],\n",
       "       [0.49074176],\n",
       "       [0.4909849 ],\n",
       "       [0.48989704],\n",
       "       [0.49100932],\n",
       "       [0.49111918],\n",
       "       [0.48800066],\n",
       "       [0.49042812],\n",
       "       [0.49109134],\n",
       "       [0.4911112 ],\n",
       "       [0.48598495],\n",
       "       [0.48927656],\n",
       "       [0.4890127 ],\n",
       "       [0.4911591 ],\n",
       "       [0.4909849 ],\n",
       "       [0.48927656],\n",
       "       [0.48285046],\n",
       "       [0.49100932],\n",
       "       [0.4850804 ],\n",
       "       [0.48721638],\n",
       "       [0.49095687],\n",
       "       [0.4908813 ],\n",
       "       [0.49113217],\n",
       "       [0.4895765 ],\n",
       "       [0.49042812],\n",
       "       [0.49113545],\n",
       "       [0.4875702 ],\n",
       "       [0.49088785],\n",
       "       [0.4846168 ],\n",
       "       [0.49060574],\n",
       "       [0.49113217],\n",
       "       [0.48684397],\n",
       "       [0.48757663],\n",
       "       [0.49032012],\n",
       "       [0.48989704],\n",
       "       [0.49095687],\n",
       "       [0.48710218],\n",
       "       [0.49075404],\n",
       "       [0.4908456 ],\n",
       "       [0.49032012],\n",
       "       [0.48841372],\n",
       "       [0.49113217],\n",
       "       [0.49054304],\n",
       "       [0.48710218],\n",
       "       [0.48383084],\n",
       "       [0.48837855],\n",
       "       [0.49113962],\n",
       "       [0.49110278],\n",
       "       [0.49074176],\n",
       "       [0.49060574],\n",
       "       [0.49113217],\n",
       "       [0.4857212 ],\n",
       "       [0.4890127 ],\n",
       "       [0.4911261 ],\n",
       "       [0.48297462],\n",
       "       [0.49111918],\n",
       "       [0.49023047],\n",
       "       [0.49042812],\n",
       "       [0.49103054],\n",
       "       [0.48533395],\n",
       "       [0.48710218],\n",
       "       [0.4908456 ],\n",
       "       [0.491142  ],\n",
       "       [0.49103054],\n",
       "       [0.4909849 ],\n",
       "       [0.48383084],\n",
       "       [0.4911572 ],\n",
       "       [0.4901969 ],\n",
       "       [0.49090597],\n",
       "       [0.49067828],\n",
       "       [0.48815998],\n",
       "       [0.49042812],\n",
       "       [0.48630866],\n",
       "       [0.49103054],\n",
       "       [0.4857212 ],\n",
       "       [0.486573  ],\n",
       "       [0.48710218],\n",
       "       [0.48800066],\n",
       "       [0.48927656],\n",
       "       [0.4908456 ],\n",
       "       [0.486573  ],\n",
       "       [0.49052283],\n",
       "       [0.4909247 ],\n",
       "       [0.49032012],\n",
       "       [0.4901969 ],\n",
       "       [0.4911112 ],\n",
       "       [0.49074176],\n",
       "       [0.49052283],\n",
       "       [0.48837855],\n",
       "       [0.48710218],\n",
       "       [0.4887146 ],\n",
       "       [0.49060574],\n",
       "       [0.4907972 ],\n",
       "       [0.486573  ],\n",
       "       [0.48030224],\n",
       "       [0.49113294],\n",
       "       [0.49032012],\n",
       "       [0.4846168 ],\n",
       "       [0.4909928 ],\n",
       "       [0.4887146 ],\n",
       "       [0.48732898],\n",
       "       [0.49105927],\n",
       "       [0.48116574],\n",
       "       [0.47945508],\n",
       "       [0.49060574],\n",
       "       [0.49105182],\n",
       "       [0.49101272],\n",
       "       [0.49054304],\n",
       "       [0.48598495],\n",
       "       [0.48383084],\n",
       "       [0.4901969 ],\n",
       "       [0.48732898],\n",
       "       [0.4890127 ],\n",
       "       [0.48757663],\n",
       "       [0.48971573],\n",
       "       [0.49100932],\n",
       "       [0.49109134],\n",
       "       [0.49067828],\n",
       "       [0.48927656],\n",
       "       [0.49067828],\n",
       "       [0.49032012],\n",
       "       [0.48989704],\n",
       "       [0.4910834 ],\n",
       "       [0.48710218],\n",
       "       [0.48732898],\n",
       "       [0.4890127 ],\n",
       "       [0.4887146 ],\n",
       "       [0.4910812 ],\n",
       "       [0.48800066],\n",
       "       [0.49111822],\n",
       "       [0.4900566 ],\n",
       "       [0.4911261 ],\n",
       "       [0.49113742],\n",
       "       [0.49060574],\n",
       "       [0.49032012],\n",
       "       [0.48950985],\n",
       "       [0.49104908],\n",
       "       [0.48971573],\n",
       "       [0.4846168 ],\n",
       "       [0.49032012],\n",
       "       [0.4901969 ],\n",
       "       [0.49109134],\n",
       "       [0.48383084],\n",
       "       [0.49319974],\n",
       "       [0.49103132],\n",
       "       [0.49113742],\n",
       "       [0.49109134],\n",
       "       [0.49107912],\n",
       "       [0.48383084],\n",
       "       [0.48438647],\n",
       "       [0.49107912],\n",
       "       [0.49109134],\n",
       "       [0.49111918],\n",
       "       [0.48757663],\n",
       "       [0.48710218],\n",
       "       [0.49113742],\n",
       "       [0.49067828],\n",
       "       [0.48757663],\n",
       "       [0.4887146 ],\n",
       "       [0.4890127 ],\n",
       "       [0.49095687],\n",
       "       [0.49032012],\n",
       "       [0.4901969 ],\n",
       "       [0.48950985],\n",
       "       [0.49116078],\n",
       "       [0.49109134],\n",
       "       [0.49095687],\n",
       "       [0.4887146 ],\n",
       "       [0.48598495],\n",
       "       [0.49088785],\n",
       "       [0.48950985],\n",
       "       [0.49134883],\n",
       "       [0.48757663],\n",
       "       [0.48971573],\n",
       "       [0.4846168 ],\n",
       "       [0.49032012],\n",
       "       [0.48438647],\n",
       "       [0.48710218],\n",
       "       [0.4908267 ],\n",
       "       [0.49062285],\n",
       "       [0.49106756],\n",
       "       [0.4907885 ],\n",
       "       [0.48630866],\n",
       "       [0.4911261 ],\n",
       "       [0.48837855],\n",
       "       [0.49095687],\n",
       "       [0.4901969 ],\n",
       "       [0.49659416],\n",
       "       [0.48837855],\n",
       "       [0.49109134],\n",
       "       [0.49115488],\n",
       "       [0.49110278],\n",
       "       [0.48757663],\n",
       "       [0.4887146 ],\n",
       "       [0.48837855],\n",
       "       [0.48837855],\n",
       "       [0.4850804 ],\n",
       "       [0.49116078],\n",
       "       [0.49100932],\n",
       "       [0.49114934],\n",
       "       [0.491142  ],\n",
       "       [0.48710218],\n",
       "       [0.49062285],\n",
       "       [0.48971573],\n",
       "       [0.49103054],\n",
       "       [0.48800066],\n",
       "       [0.49109134],\n",
       "       [0.49107912],\n",
       "       [0.49113217],\n",
       "       [0.49052283],\n",
       "       [0.49113962],\n",
       "       [0.49042812],\n",
       "       [0.48950985],\n",
       "       [0.4909849 ],\n",
       "       [0.48971573],\n",
       "       [0.486573  ],\n",
       "       [0.4907972 ],\n",
       "       [0.4890127 ],\n",
       "       [0.49042812],\n",
       "       [0.49052283],\n",
       "       [0.48971573],\n",
       "       [0.49163488],\n",
       "       [0.4909247 ],\n",
       "       [0.48837855],\n",
       "       [0.49109134],\n",
       "       [0.49110195],\n",
       "       [0.48989704],\n",
       "       [0.49095687],\n",
       "       [0.48800066],\n",
       "       [0.4908456 ],\n",
       "       [0.4909247 ],\n",
       "       [0.4910297 ],\n",
       "       [0.4908456 ],\n",
       "       [0.48757663],\n",
       "       [0.49100932],\n",
       "       [0.48971573],\n",
       "       [0.49110195],\n",
       "       [0.48710218],\n",
       "       [0.48757663],\n",
       "       [0.48598495],\n",
       "       [0.48837855],\n",
       "       [0.48837855],\n",
       "       [0.48927656],\n",
       "       [0.48950985],\n",
       "       [0.48971573],\n",
       "       [0.48630866],\n",
       "       [0.4887146 ],\n",
       "       [0.4910651 ],\n",
       "       [0.49110195],\n",
       "       [0.48989704],\n",
       "       [0.48800066],\n",
       "       [0.48800066],\n",
       "       [0.48971573],\n",
       "       [0.4909928 ],\n",
       "       [0.4887146 ],\n",
       "       [0.4890127 ],\n",
       "       [0.4910812 ],\n",
       "       [0.4925308 ],\n",
       "       [0.4910719 ],\n",
       "       [0.4890127 ]], dtype=float32)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_job_categroy_wave1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4874366 ],\n",
       "       [0.4870615 ],\n",
       "       [0.4877552 ],\n",
       "       [0.4798993 ],\n",
       "       [0.48575792],\n",
       "       [0.4870615 ],\n",
       "       [0.47700918],\n",
       "       [0.48777547],\n",
       "       [0.48781624],\n",
       "       [0.48776588],\n",
       "       [0.48778644],\n",
       "       [0.48776588],\n",
       "       [0.48773542],\n",
       "       [0.48781833],\n",
       "       [0.487127  ],\n",
       "       [0.4877077 ],\n",
       "       [0.4846481 ],\n",
       "       [0.48660582],\n",
       "       [0.48782   ],\n",
       "       [0.48780903],\n",
       "       [0.4877505 ],\n",
       "       [0.48615637],\n",
       "       [0.48772153],\n",
       "       [0.48549968],\n",
       "       [0.48780796],\n",
       "       [0.48780385],\n",
       "       [0.48571512],\n",
       "       [0.48605603],\n",
       "       [0.48676008],\n",
       "       [0.48776403],\n",
       "       [0.4848277 ],\n",
       "       [0.4870615 ],\n",
       "       [0.4878026 ],\n",
       "       [0.4878122 ],\n",
       "       [0.48644176],\n",
       "       [0.4877552 ],\n",
       "       [0.48782107],\n",
       "       [0.4877404 ],\n",
       "       [0.4823479 ],\n",
       "       [0.4874755 ],\n",
       "       [0.48766166],\n",
       "       [0.4877912 ],\n",
       "       [0.48669627],\n",
       "       [0.48776403],\n",
       "       [0.48781124],\n",
       "       [0.48339912],\n",
       "       [0.48730853],\n",
       "       [0.4877995 ],\n",
       "       [0.48780856],\n",
       "       [0.47820795],\n",
       "       [0.48579642],\n",
       "       [0.48608953],\n",
       "       [0.48782244],\n",
       "       [0.4877511 ],\n",
       "       [0.4863975 ],\n",
       "       [0.46885657],\n",
       "       [0.48776403],\n",
       "       [0.47120637],\n",
       "       [0.467711  ],\n",
       "       [0.48772833],\n",
       "       [0.487127  ],\n",
       "       [0.4878153 ],\n",
       "       [0.48723248],\n",
       "       [0.4874952 ],\n",
       "       [0.48781404],\n",
       "       [0.48275992],\n",
       "       [0.4875464 ],\n",
       "       [0.47877634],\n",
       "       [0.4874755 ],\n",
       "       [0.4878178 ],\n",
       "       [0.4847081 ],\n",
       "       [0.48540777],\n",
       "       [0.4864951 ],\n",
       "       [0.48703077],\n",
       "       [0.48776165],\n",
       "       [0.4812961 ],\n",
       "       [0.48769304],\n",
       "       [0.4874864 ],\n",
       "       [0.4871971 ],\n",
       "       [0.47820795],\n",
       "       [0.48781464],\n",
       "       [0.48747283],\n",
       "       [0.4812961 ],\n",
       "       [0.47594556],\n",
       "       [0.4801385 ],\n",
       "       [0.4878179 ],\n",
       "       [0.487798  ],\n",
       "       [0.48747283],\n",
       "       [0.48735285],\n",
       "       [0.4878153 ],\n",
       "       [0.47410664],\n",
       "       [0.48612466],\n",
       "       [0.4878135 ],\n",
       "       [0.47342744],\n",
       "       [0.48781517],\n",
       "       [0.48755363],\n",
       "       [0.48746148],\n",
       "       [0.48778924],\n",
       "       [0.482568  ],\n",
       "       [0.47410664],\n",
       "       [0.48758662],\n",
       "       [0.48781756],\n",
       "       [0.48771963],\n",
       "       [0.4877511 ],\n",
       "       [0.47685772],\n",
       "       [0.48782232],\n",
       "       [0.48700047],\n",
       "       [0.48753202],\n",
       "       [0.48751456],\n",
       "       [0.48449433],\n",
       "       [0.487127  ],\n",
       "       [0.48244867],\n",
       "       [0.48771963],\n",
       "       [0.47902614],\n",
       "       [0.4823479 ],\n",
       "       [0.48331597],\n",
       "       [0.48339912],\n",
       "       [0.48579642],\n",
       "       [0.4876725 ],\n",
       "       [0.4823479 ],\n",
       "       [0.48692545],\n",
       "       [0.4877163 ],\n",
       "       [0.4873921 ],\n",
       "       [0.48620805],\n",
       "       [0.48779157],\n",
       "       [0.4875884 ],\n",
       "       [0.4874002 ],\n",
       "       [0.48436245],\n",
       "       [0.48077157],\n",
       "       [0.4855454 ],\n",
       "       [0.48757896],\n",
       "       [0.48763034],\n",
       "       [0.47926208],\n",
       "       [0.47038862],\n",
       "       [0.48781905],\n",
       "       [0.48714682],\n",
       "       [0.4809079 ],\n",
       "       [0.48304394],\n",
       "       [0.4845873 ],\n",
       "       [0.48549968],\n",
       "       [0.4876363 ],\n",
       "       [0.4601372 ],\n",
       "       [0.46840042],\n",
       "       [0.4875839 ],\n",
       "       [0.48781368],\n",
       "       [0.48766473],\n",
       "       [0.4875884 ],\n",
       "       [0.4774339 ],\n",
       "       [0.47685772],\n",
       "       [0.48728785],\n",
       "       [0.48240528],\n",
       "       [0.4851613 ],\n",
       "       [0.48244867],\n",
       "       [0.4864526 ],\n",
       "       [0.48778567],\n",
       "       [0.4877995 ],\n",
       "       [0.4872166 ],\n",
       "       [0.48653036],\n",
       "       [0.4876412 ],\n",
       "       [0.4871971 ],\n",
       "       [0.48731795],\n",
       "       [0.48778567],\n",
       "       [0.47812906],\n",
       "       [0.48605603],\n",
       "       [0.4866282 ],\n",
       "       [0.48591182],\n",
       "       [0.48780856],\n",
       "       [0.48304394],\n",
       "       [0.48779646],\n",
       "       [0.48682237],\n",
       "       [0.48780987],\n",
       "       [0.48781338],\n",
       "       [0.48730445],\n",
       "       [0.48688936],\n",
       "       [0.48615637],\n",
       "       [0.48773816],\n",
       "       [0.4864526 ],\n",
       "       [0.4814472 ],\n",
       "       [0.4873831 ],\n",
       "       [0.48620805],\n",
       "       [0.48780826],\n",
       "       [0.4800915 ],\n",
       "       [0.47877634],\n",
       "       [0.4877505 ],\n",
       "       [0.48780903],\n",
       "       [0.48780826],\n",
       "       [0.48778304],\n",
       "       [0.4648929 ],\n",
       "       [0.48167628],\n",
       "       [0.48779646],\n",
       "       [0.48779342],\n",
       "       [0.48781577],\n",
       "       [0.48540777],\n",
       "       [0.48331597],\n",
       "       [0.48780903],\n",
       "       [0.4872166 ],\n",
       "       [0.48244867],\n",
       "       [0.4845873 ],\n",
       "       [0.48535907],\n",
       "       [0.4876363 ],\n",
       "       [0.48697633],\n",
       "       [0.48700047],\n",
       "       [0.4842942 ],\n",
       "       [0.48782256],\n",
       "       [0.48780128],\n",
       "       [0.48773542],\n",
       "       [0.4848277 ],\n",
       "       [0.4811741 ],\n",
       "       [0.48769304],\n",
       "       [0.48602265],\n",
       "       [0.48331597],\n",
       "       [0.48201698],\n",
       "       [0.48694915],\n",
       "       [0.47877634],\n",
       "       [0.4874241 ],\n",
       "       [0.4811741 ],\n",
       "       [0.47410664],\n",
       "       [0.48591182],\n",
       "       [0.4877004 ],\n",
       "       [0.48780528],\n",
       "       [0.48535907],\n",
       "       [0.48057488],\n",
       "       [0.48781714],\n",
       "       [0.48418245],\n",
       "       [0.48770425],\n",
       "       [0.48679316],\n",
       "       [0.47175345],\n",
       "       [0.48418245],\n",
       "       [0.4877762 ],\n",
       "       [0.48782256],\n",
       "       [0.48778334],\n",
       "       [0.48403746],\n",
       "       [0.4837777 ],\n",
       "       [0.48418245],\n",
       "       [0.4829083 ],\n",
       "       [0.4823479 ],\n",
       "       [0.48782226],\n",
       "       [0.487743  ],\n",
       "       [0.48781553],\n",
       "       [0.48781756],\n",
       "       [0.48077157],\n",
       "       [0.48741338],\n",
       "       [0.4864526 ],\n",
       "       [0.4877924 ],\n",
       "       [0.4818534 ],\n",
       "       [0.4877995 ],\n",
       "       [0.48776588],\n",
       "       [0.48781833],\n",
       "       [0.487502  ],\n",
       "       [0.4878153 ],\n",
       "       [0.48673123],\n",
       "       [0.48602265],\n",
       "       [0.48766968],\n",
       "       [0.48634267],\n",
       "       [0.47120637],\n",
       "       [0.48763034],\n",
       "       [0.48625115],\n",
       "       [0.48726726],\n",
       "       [0.4874002 ],\n",
       "       [0.48678192],\n",
       "       [0.48275992],\n",
       "       [0.4877163 ],\n",
       "       [0.4801385 ],\n",
       "       [0.4877762 ],\n",
       "       [0.48779622],\n",
       "       [0.48660582],\n",
       "       [0.4876363 ],\n",
       "       [0.4847081 ],\n",
       "       [0.4874864 ],\n",
       "       [0.48759577],\n",
       "       [0.4877404 ],\n",
       "       [0.48772234],\n",
       "       [0.48439145],\n",
       "       [0.48778263],\n",
       "       [0.48694915],\n",
       "       [0.48779622],\n",
       "       [0.47902614],\n",
       "       [0.476509  ],\n",
       "       [0.48167628],\n",
       "       [0.48418245],\n",
       "       [0.48418245],\n",
       "       [0.48579642],\n",
       "       [0.48615637],\n",
       "       [0.48685935],\n",
       "       [0.48244867],\n",
       "       [0.4848277 ],\n",
       "       [0.48775336],\n",
       "       [0.487811  ],\n",
       "       [0.48669627],\n",
       "       [0.48339912],\n",
       "       [0.48339912],\n",
       "       [0.4872085 ],\n",
       "       [0.48499912],\n",
       "       [0.4848277 ],\n",
       "       [0.48535907],\n",
       "       [0.48779157],\n",
       "       [0.48036388],\n",
       "       [0.48775467],\n",
       "       [0.48261255]], dtype=float32)"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_environment_wave1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5052856 ],\n",
       "       [0.5052857 ],\n",
       "       [0.50528556],\n",
       "       [0.5052927 ],\n",
       "       [0.50528693],\n",
       "       [0.5052857 ],\n",
       "       [0.5053029 ],\n",
       "       [0.50528556],\n",
       "       [0.50530106],\n",
       "       [0.50528556],\n",
       "       [0.5052892 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052857 ],\n",
       "       [0.50528556],\n",
       "       [0.50530106],\n",
       "       [0.50528616],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528604],\n",
       "       [0.5052957 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528693],\n",
       "       [0.5052875 ],\n",
       "       [0.50528663],\n",
       "       [0.50528556],\n",
       "       [0.5052892 ],\n",
       "       [0.5052857 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528574],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50530434],\n",
       "       [0.5052856 ],\n",
       "       [0.50528556],\n",
       "       [0.5052858 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052883 ],\n",
       "       [0.5052856 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50529534],\n",
       "       [0.5052863 ],\n",
       "       [0.50528556],\n",
       "       [0.5052863 ],\n",
       "       [0.5053498 ],\n",
       "       [0.50528556],\n",
       "       [0.50530773],\n",
       "       [0.50530785],\n",
       "       [0.50528556],\n",
       "       [0.5052858 ],\n",
       "       [0.50528556],\n",
       "       [0.505286  ],\n",
       "       [0.5052856 ],\n",
       "       [0.50528556],\n",
       "       [0.5053015 ],\n",
       "       [0.50528556],\n",
       "       [0.5053029 ],\n",
       "       [0.5052856 ],\n",
       "       [0.5052931 ],\n",
       "       [0.5052856 ],\n",
       "       [0.5052858 ],\n",
       "       [0.50528556],\n",
       "       [0.5052908 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.5053124 ],\n",
       "       [0.50528556],\n",
       "       [0.5052908 ],\n",
       "       [0.5053083 ],\n",
       "       [0.5052875 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.50528556],\n",
       "       [0.50530106],\n",
       "       [0.5052866 ],\n",
       "       [0.50528556],\n",
       "       [0.5053147 ],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.5052856 ],\n",
       "       [0.50528556],\n",
       "       [0.5052987 ],\n",
       "       [0.5052908 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5053083 ],\n",
       "       [0.50528556],\n",
       "       [0.50528675],\n",
       "       [0.5052857 ],\n",
       "       [0.50528574],\n",
       "       [0.5052856 ],\n",
       "       [0.5052881 ],\n",
       "       [0.5052856 ],\n",
       "       [0.5052964 ],\n",
       "       [0.50528556],\n",
       "       [0.50530106],\n",
       "       [0.5052927 ],\n",
       "       [0.5052908 ],\n",
       "       [0.5052883 ],\n",
       "       [0.5052863 ],\n",
       "       [0.50528556],\n",
       "       [0.5052927 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.5052857 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052875 ],\n",
       "       [0.5052908 ],\n",
       "       [0.50528693],\n",
       "       [0.5052856 ],\n",
       "       [0.50528556],\n",
       "       [0.5052927 ],\n",
       "       [0.5054693 ],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.5053029 ],\n",
       "       [0.5053001 ],\n",
       "       [0.50528693],\n",
       "       [0.5052908 ],\n",
       "       [0.50528556],\n",
       "       [0.5054153 ],\n",
       "       [0.5055454 ],\n",
       "       [0.5052856 ],\n",
       "       [0.5052856 ],\n",
       "       [0.5052856 ],\n",
       "       [0.50529534],\n",
       "       [0.5053083 ],\n",
       "       [0.5052857 ],\n",
       "       [0.5052908 ],\n",
       "       [0.5052866 ],\n",
       "       [0.5052894 ],\n",
       "       [0.5052859 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.5052863 ],\n",
       "       [0.5052856 ],\n",
       "       [0.5052856 ],\n",
       "       [0.5052858 ],\n",
       "       [0.5054153 ],\n",
       "       [0.50528556],\n",
       "       [0.5052908 ],\n",
       "       [0.50528693],\n",
       "       [0.50528556],\n",
       "       [0.5052883 ],\n",
       "       [0.50528556],\n",
       "       [0.50528574],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.50528604],\n",
       "       [0.50528556],\n",
       "       [0.5052859 ],\n",
       "       [0.5053029 ],\n",
       "       [0.5052856 ],\n",
       "       [0.5052857 ],\n",
       "       [0.50528556],\n",
       "       [0.5053083 ],\n",
       "       [0.5054097 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5053083 ],\n",
       "       [0.5053173 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052908 ],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.5052894 ],\n",
       "       [0.50528693],\n",
       "       [0.5052866 ],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.5052857 ],\n",
       "       [0.50528604],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528693],\n",
       "       [0.50529534],\n",
       "       [0.50528556],\n",
       "       [0.50528604],\n",
       "       [0.5053155 ],\n",
       "       [0.5052894 ],\n",
       "       [0.5052859 ],\n",
       "       [0.5053029 ],\n",
       "       [0.5052856 ],\n",
       "       [0.5053173 ],\n",
       "       [0.5052908 ],\n",
       "       [0.50529265],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052905 ],\n",
       "       [0.5052964 ],\n",
       "       [0.50528556],\n",
       "       [0.5052875 ],\n",
       "       [0.50528556],\n",
       "       [0.5052857 ],\n",
       "       [0.5056422 ],\n",
       "       [0.5052875 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052894 ],\n",
       "       [0.50528693],\n",
       "       [0.5052875 ],\n",
       "       [0.5052875 ],\n",
       "       [0.50530773],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052908 ],\n",
       "       [0.50528556],\n",
       "       [0.5052859 ],\n",
       "       [0.50528556],\n",
       "       [0.5052883 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052856 ],\n",
       "       [0.50528604],\n",
       "       [0.50528556],\n",
       "       [0.5052859 ],\n",
       "       [0.5052927 ],\n",
       "       [0.50528556],\n",
       "       [0.5052866 ],\n",
       "       [0.5052856 ],\n",
       "       [0.50528556],\n",
       "       [0.5052859 ],\n",
       "       [0.50532824],\n",
       "       [0.50528556],\n",
       "       [0.5052875 ],\n",
       "       [0.50528556],\n",
       "       [0.5052858 ],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052894 ],\n",
       "       [0.50528556],\n",
       "       [0.5052859 ],\n",
       "       [0.5052908 ],\n",
       "       [0.5052894 ],\n",
       "       [0.50529534],\n",
       "       [0.5052875 ],\n",
       "       [0.5052875 ],\n",
       "       [0.5052863 ],\n",
       "       [0.50528604],\n",
       "       [0.5052859 ],\n",
       "       [0.5052964 ],\n",
       "       [0.50528693],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052858 ],\n",
       "       [0.5052883 ],\n",
       "       [0.5052883 ],\n",
       "       [0.5052859 ],\n",
       "       [0.5053001 ],\n",
       "       [0.50528693],\n",
       "       [0.5052866 ],\n",
       "       [0.50528556],\n",
       "       [0.50537264],\n",
       "       [0.50528556],\n",
       "       [0.5052866 ],\n",
       "       [0.50528574],\n",
       "       [0.50528556],\n",
       "       [0.50528556],\n",
       "       [0.5052883 ],\n",
       "       [0.50528556],\n",
       "       [0.50528616],\n",
       "       [0.50528556],\n",
       "       [0.5054693 ],\n",
       "       [0.50528556],\n",
       "       [0.5052908 ],\n",
       "       [0.5052894 ],\n",
       "       [0.5052856 ]], dtype=float32)"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_job_categroy_wave2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5009407 ],\n",
       "       [0.49900123],\n",
       "       [0.50068325],\n",
       "       [0.49242285],\n",
       "       [0.50065035],\n",
       "       [0.49900123],\n",
       "       [0.5020136 ],\n",
       "       [0.50068325],\n",
       "       [0.49305603],\n",
       "       [0.50152445],\n",
       "       [0.49566665],\n",
       "       [0.5014489 ],\n",
       "       [0.5013257 ],\n",
       "       [0.5014489 ],\n",
       "       [0.50088334],\n",
       "       [0.5014166 ],\n",
       "       [0.5007222 ],\n",
       "       [0.5011673 ],\n",
       "       [0.502093  ],\n",
       "       [0.5002492 ],\n",
       "       [0.50158566],\n",
       "       [0.5015589 ],\n",
       "       [0.50154346],\n",
       "       [0.50137955],\n",
       "       [0.4975479 ],\n",
       "       [0.4950705 ],\n",
       "       [0.5012981 ],\n",
       "       [0.5014513 ],\n",
       "       [0.49601772],\n",
       "       [0.50084764],\n",
       "       [0.49720916],\n",
       "       [0.5010379 ],\n",
       "       [0.49601772],\n",
       "       [0.49900123],\n",
       "       [0.50115496],\n",
       "       [0.5014694 ],\n",
       "       [0.5004518 ],\n",
       "       [0.50068325],\n",
       "       [0.501533  ],\n",
       "       [0.5005686 ],\n",
       "       [0.50282896],\n",
       "       [0.49995723],\n",
       "       [0.50092405],\n",
       "       [0.49834815],\n",
       "       [0.5010379 ],\n",
       "       [0.5013947 ],\n",
       "       [0.49474463],\n",
       "       [0.49953052],\n",
       "       [0.5014313 ],\n",
       "       [0.5013662 ],\n",
       "       [0.49154213],\n",
       "       [0.4970849 ],\n",
       "       [0.5009651 ],\n",
       "       [0.4970849 ],\n",
       "       [0.5019202 ],\n",
       "       [0.5010379 ],\n",
       "       [0.49928793],\n",
       "       [0.49930778],\n",
       "       [0.50121284],\n",
       "       [0.5007222 ],\n",
       "       [0.5014424 ],\n",
       "       [0.49840268],\n",
       "       [0.49929962],\n",
       "       [0.5013299 ],\n",
       "       [0.49232587],\n",
       "       [0.50120074],\n",
       "       [0.4901149 ],\n",
       "       [0.49995723],\n",
       "       [0.49474463],\n",
       "       [0.50065446],\n",
       "       [0.49834815],\n",
       "       [0.50088334],\n",
       "       [0.49325177],\n",
       "       [0.50068873],\n",
       "       [0.5011525 ],\n",
       "       [0.49928   ],\n",
       "       [0.49154213],\n",
       "       [0.5015129 ],\n",
       "       [0.49325177],\n",
       "       [0.50866324],\n",
       "       [0.49959537],\n",
       "       [0.5015002 ],\n",
       "       [0.50068325],\n",
       "       [0.501097  ],\n",
       "       [0.5010408 ],\n",
       "       [0.50087255],\n",
       "       [0.5014424 ],\n",
       "       [0.4993197 ],\n",
       "       [0.50052416],\n",
       "       [0.50141996],\n",
       "       [0.51120394],\n",
       "       [0.50147027],\n",
       "       [0.49954328],\n",
       "       [0.49953052],\n",
       "       [0.5011028 ],\n",
       "       [0.4908379 ],\n",
       "       [0.4993197 ],\n",
       "       [0.5011525 ],\n",
       "       [0.5015348 ],\n",
       "       [0.50137955],\n",
       "       [0.5009651 ],\n",
       "       [0.48943886],\n",
       "       [0.5015313 ],\n",
       "       [0.49720916],\n",
       "       [0.50044245],\n",
       "       [0.5007324 ],\n",
       "       [0.500868  ],\n",
       "       [0.50007623],\n",
       "       [0.5007222 ],\n",
       "       [0.4940261 ],\n",
       "       [0.50137955],\n",
       "       [0.5002465 ],\n",
       "       [0.50282896],\n",
       "       [0.502093  ],\n",
       "       [0.49474463],\n",
       "       [0.4970849 ],\n",
       "       [0.5011164 ],\n",
       "       [0.50282896],\n",
       "       [0.500829  ],\n",
       "       [0.5007916 ],\n",
       "       [0.5006033 ],\n",
       "       [0.50055665],\n",
       "       [0.50149864],\n",
       "       [0.50029963],\n",
       "       [0.49975553],\n",
       "       [0.50001764],\n",
       "       [0.50011486],\n",
       "       [0.49986747],\n",
       "       [0.49995723],\n",
       "       [0.50044423],\n",
       "       [0.5003671 ],\n",
       "       [0.514368  ],\n",
       "       [0.50149566],\n",
       "       [0.5005362 ],\n",
       "       [0.5066397 ],\n",
       "       [0.4998773 ],\n",
       "       [0.49986747],\n",
       "       [0.4950705 ],\n",
       "       [0.50128365],\n",
       "       [0.50392914],\n",
       "       [0.4880797 ],\n",
       "       [0.500798  ],\n",
       "       [0.50057334],\n",
       "       [0.50029963],\n",
       "       [0.5007435 ],\n",
       "       [0.48943886],\n",
       "       [0.49900123],\n",
       "       [0.49959537],\n",
       "       [0.49991372],\n",
       "       [0.4940261 ],\n",
       "       [0.497968  ],\n",
       "       [0.50095904],\n",
       "       [0.5014313 ],\n",
       "       [0.5009765 ],\n",
       "       [0.49673566],\n",
       "       [0.4999605 ],\n",
       "       [0.49928   ],\n",
       "       [0.4980407 ],\n",
       "       [0.4888439 ],\n",
       "       [0.50095904],\n",
       "       [0.50084764],\n",
       "       [0.49566665],\n",
       "       [0.5013662 ],\n",
       "       [0.4998773 ],\n",
       "       [0.5012575 ],\n",
       "       [0.50034624],\n",
       "       [0.5015114 ],\n",
       "       [0.50154346],\n",
       "       [0.50090593],\n",
       "       [0.4975479 ],\n",
       "       [0.50140524],\n",
       "       [0.497968  ],\n",
       "       [0.4901149 ],\n",
       "       [0.49928   ],\n",
       "       [0.50055665],\n",
       "       [0.5014116 ],\n",
       "       [0.48943886],\n",
       "       [0.4901149 ],\n",
       "       [0.50154346],\n",
       "       [0.5014116 ],\n",
       "       [0.5014489 ],\n",
       "       [0.50278836],\n",
       "       [0.49158147],\n",
       "       [0.5012575 ],\n",
       "       [0.5014494 ],\n",
       "       [0.50136226],\n",
       "       [0.502093  ],\n",
       "       [0.50154346],\n",
       "       [0.5009765 ],\n",
       "       [0.4940261 ],\n",
       "       [0.49986747],\n",
       "       [0.49657574],\n",
       "       [0.50128365],\n",
       "       [0.5006408 ],\n",
       "       [0.50044245],\n",
       "       [0.5000997 ],\n",
       "       [0.5012981 ],\n",
       "       [0.50088334],\n",
       "       [0.49601772],\n",
       "       [0.50379395],\n",
       "       [0.50068873],\n",
       "       [0.5000631 ],\n",
       "       [0.502093  ],\n",
       "       [0.49995902],\n",
       "       [0.49764362],\n",
       "       [0.4901149 ],\n",
       "       [0.4990299 ],\n",
       "       [0.50379395],\n",
       "       [0.4993197 ],\n",
       "       [0.49566665],\n",
       "       [0.5002976 ],\n",
       "       [0.50133413],\n",
       "       [0.49657574],\n",
       "       [0.50010985],\n",
       "       [0.5013911 ],\n",
       "       [0.49540803],\n",
       "       [0.5012521 ],\n",
       "       [0.500556  ],\n",
       "       [0.4883729 ],\n",
       "       [0.49540803],\n",
       "       [0.5014674 ],\n",
       "       [0.5015201 ],\n",
       "       [0.5011605 ],\n",
       "       [0.4940261 ],\n",
       "       [0.5000335 ],\n",
       "       [0.49540803],\n",
       "       [0.50001764],\n",
       "       [0.50282896],\n",
       "       [0.5015589 ],\n",
       "       [0.5013234 ],\n",
       "       [0.5015658 ],\n",
       "       [0.5015348 ],\n",
       "       [0.50011486],\n",
       "       [0.5010994 ],\n",
       "       [0.497968  ],\n",
       "       [0.501032  ],\n",
       "       [0.50003886],\n",
       "       [0.5014313 ],\n",
       "       [0.5014489 ],\n",
       "       [0.5014166 ],\n",
       "       [0.5014424 ],\n",
       "       [0.5007451 ],\n",
       "       [0.5000631 ],\n",
       "       [0.501319  ],\n",
       "       [0.50015384],\n",
       "       [0.49928793],\n",
       "       [0.50044423],\n",
       "       [0.49622175],\n",
       "       [0.5006263 ],\n",
       "       [0.49975553],\n",
       "       [0.50015384],\n",
       "       [0.49232587],\n",
       "       [0.5007916 ],\n",
       "       [0.49959537],\n",
       "       [0.5014674 ],\n",
       "       [0.5002492 ],\n",
       "       [0.50128365],\n",
       "       [0.5011525 ],\n",
       "       [0.5012443 ],\n",
       "       [0.5005686 ],\n",
       "       [0.5004406 ],\n",
       "       [0.4937614 ],\n",
       "       [0.5012654 ],\n",
       "       [0.49764362],\n",
       "       [0.5002465 ],\n",
       "       [0.49938866],\n",
       "       [0.49158147],\n",
       "       [0.49540803],\n",
       "       [0.49540803],\n",
       "       [0.4970849 ],\n",
       "       [0.4975479 ],\n",
       "       [0.497968  ],\n",
       "       [0.4940261 ],\n",
       "       [0.49601772],\n",
       "       [0.50142825],\n",
       "       [0.5014332 ],\n",
       "       [0.49834815],\n",
       "       [0.49474463],\n",
       "       [0.49474463],\n",
       "       [0.49764362],\n",
       "       [0.49443445],\n",
       "       [0.49601772],\n",
       "       [0.49657574],\n",
       "       [0.50149864],\n",
       "       [0.4908379 ],\n",
       "       [0.5012895 ],\n",
       "       [0.49984464],\n",
       "       [0.500469  ],\n",
       "       [0.50068325],\n",
       "       [0.5011164 ],\n",
       "       [0.49474463],\n",
       "       [0.500829  ],\n",
       "       [0.5004502 ],\n",
       "       [0.50140667],\n",
       "       [0.50540507],\n",
       "       [0.5013004 ],\n",
       "       [0.4993197 ],\n",
       "       [0.4937614 ],\n",
       "       [0.49900118]], dtype=float32)"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_environment_wave2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
