{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the `TensorFlow` and `numpy` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our neural network to \"learn\" the relationship between list of inputs and list of outputs\n",
    "\n",
    "**Example**\n",
    "Here `x` represents the input array, which is a 2D array with 4 column (input) variables. `y` represents the output variable, which is 1D array with 1 output value per row in the `x` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 1.0, 4.5, 2.3, 6.7, 1.0], dtype=float)\n",
    "y = np.array([-3.0, -1.0, 1.0, 3.0, 4.0, 2.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>student</th>\n",
       "      <th>wfh_now</th>\n",
       "      <th>prod_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Increased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Decreased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Decreased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Decreased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes, Full-time</td>\n",
       "      <td>Yes</td>\n",
       "      <td>In some ways it has increased and in other way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>9319</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Question not displayed to respondent</td>\n",
       "      <td>Question not displayed to respondent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>9322</td>\n",
       "      <td>47</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Increased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>9323</td>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>About the same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>9325</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Decreased somewhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>9337</td>\n",
       "      <td>71</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Question not displayed to respondent</td>\n",
       "      <td>Question not displayed to respondent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2905 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      resp_id  age  gender         student  \\\n",
       "0          11   44    Male              No   \n",
       "1          29   39    Male              No   \n",
       "2          30   49  Female              No   \n",
       "3          31   27    Male              No   \n",
       "4          34   32  Female  Yes, Full-time   \n",
       "...       ...  ...     ...             ...   \n",
       "2900     9319   67    Male              No   \n",
       "2901     9322   47  Female              No   \n",
       "2902     9323   59    Male              No   \n",
       "2903     9325   60  Female              No   \n",
       "2904     9337   71    Male              No   \n",
       "\n",
       "                                   wfh_now  \\\n",
       "0                                      Yes   \n",
       "1                                      Yes   \n",
       "2                                      Yes   \n",
       "3                                      Yes   \n",
       "4                                      Yes   \n",
       "...                                    ...   \n",
       "2900  Question not displayed to respondent   \n",
       "2901                                    No   \n",
       "2902                                    No   \n",
       "2903                                    No   \n",
       "2904  Question not displayed to respondent   \n",
       "\n",
       "                                            prod_change  \n",
       "0                                    Increased somewhat  \n",
       "1                                    Decreased somewhat  \n",
       "2                                    Decreased somewhat  \n",
       "3                                    Decreased somewhat  \n",
       "4     In some ways it has increased and in other way...  \n",
       "...                                                 ...  \n",
       "2900               Question not displayed to respondent  \n",
       "2901                                 Increased somewhat  \n",
       "2902                                     About the same  \n",
       "2903                                 Decreased somewhat  \n",
       "2904               Question not displayed to respondent  \n",
       "\n",
       "[2905 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data = data.loc[:,['resp_id', 'age', 'gender', 'student', 'wfh_now', 'prod_change']]\n",
    "data.columns = data.columns.to_series().apply(lambda x: x.strip())\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up data\n",
    "\n",
    "We now have to convert the data from text to decimal values, to provide consistency over all the columns which will help the model fit our data.\n",
    "\n",
    "Gender: 0 Male, 1 Female\n",
    "\n",
    "Student: 0 Not a student, 1 Student Full time, 2 Student Part time\n",
    "\n",
    "WFH_Now: 0 No, 1 Yes\n",
    "\n",
    "Prod_Change: 0 Decreased Significantly, 1 Decreased Somewhat, 2 Both, 3 Same, 4 Increased somewhat, 5 Increased significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>student</th>\n",
       "      <th>wfh_now</th>\n",
       "      <th>prod_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>9280</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>9281</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>9286</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>9322</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>9325</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      resp_id  age gender student wfh_now prod_change\n",
       "0          11   44      0       0       1           4\n",
       "1          29   39      0       0       1           1\n",
       "2          30   49      1       0       1           1\n",
       "3          31   27      0       0       1           1\n",
       "10         46   63      1       0       1           4\n",
       "...       ...  ...    ...     ...     ...         ...\n",
       "2887     9280   61      1       0       1           4\n",
       "2888     9281   65      1       0       1           4\n",
       "2890     9286   67      0       0       1           4\n",
       "2901     9322   47      1       0       0           4\n",
       "2903     9325   60      1       0       0           1\n",
       "\n",
       "[616 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genders = {\n",
    "  'Male' : 0,\n",
    "  'Female' : 1,\n",
    "}\n",
    "\n",
    "Student = {\n",
    "  'No' : 0,\n",
    "  'Yes' : 1,\n",
    "}\n",
    "\n",
    "WFH_Now = {\n",
    "  'No' : 0,\n",
    "  'Yes' : 1,\n",
    "}\n",
    "\n",
    "Prod_Change = {\n",
    "  'Decreased significantly': 0,\n",
    "  'Decreased somewhat': 1,\n",
    "  'Both': 2,\n",
    "  'Same': 3,\n",
    "  'Increased somewhat': 4,\n",
    "  'Increased significantly': 5,\n",
    "}\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "  # print(index)\n",
    "  gender = row['gender']\n",
    "  student = row['student']\n",
    "  wfh_now = row['wfh_now']\n",
    "  prod_change = row['prod_change']\n",
    "\n",
    "  data.loc[index, 'gender'] = Genders.get(gender, -1)\n",
    "  data.loc[index, 'student'] = Student.get(student, -1)\n",
    "  data.loc[index, 'wfh_now'] = WFH_Now.get(wfh_now, -1)\n",
    "  data.loc[index, 'prod_change'] = Prod_Change.get(prod_change, -1)\n",
    "  \n",
    "  # drop all the rows that have missing values (aka have a -1 in any column)\n",
    "  if (data.loc[index, 'gender'] == -1 or data.loc[index, 'student']==-1 or data.loc[index, 'wfh_now']==-1 or data.loc[index, 'prod_change']==-1):\n",
    "    data.drop(labels=index, axis=0, inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the simplest possible neural network. It has 1 layer, that layer has 1 neuron, and the input is just 1 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compile the neural network by specifying a **loss function** and an **optimization algorithm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now **train** our neural network to fit the data. The neural network will try to guess the relationship between the values in `x` and the values in `y`. The loss function will measure how good or how bad this guess is and, based on this, the optimization algorithm will make another guess. We then repeat this process for a certin number of iterations (`epochs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 0s 491us/step - loss: 5.2910\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 488us/step - loss: 4.5662\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 459us/step - loss: 4.2427\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 450us/step - loss: 4.0728\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 426us/step - loss: 3.9461\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 417us/step - loss: 3.8441\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 411us/step - loss: 3.7593\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 404us/step - loss: 3.6860\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 400us/step - loss: 3.6211\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 396us/step - loss: 3.5670\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 421us/step - loss: 3.5184\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 413us/step - loss: 3.4733\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 409us/step - loss: 3.4364\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 397us/step - loss: 3.4077\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 424us/step - loss: 3.3786\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 424us/step - loss: 3.3558\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 411us/step - loss: 3.3350\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 440us/step - loss: 3.3142\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 401us/step - loss: 3.2984\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 409us/step - loss: 3.2850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f92f130>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.loc[:,['gender']]\n",
    "y = data.loc[:,['prod_change']]\n",
    "\n",
    "x = np.asarray(x).astype('float32')\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "model.fit(x, y, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test our neural network by using it to predict the value of `prod_change` for a previously unseen value of `gender` (for example, `gender=1`). **What do you think the value of `prod_change` will be?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[2.4382176]\n",
      " [1.9966186]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([1.0,0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reasonable prediction since we only used binary gender as input and productivity levels (0-5) as output. And we currently assume no correlation between the two categories but we will improve our model but adding more features and improving the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "* The most challenging part of this project is estimating individual productivity since there are many factors that could affect human behvaior, it's hard to draw conclusion, and it's also hard to use all the features from our survey data to simply predict productivity.\n",
    "* Our initial insights is that workplace productivity is affected when people change scenes and switch between working in person to working from home. And the choice to work from home is fueled by other factors including education, income, job type, etc. \n",
    "* We don't have concrete results yet because we cleaned up the data and found out we might not have enough data of a certain feature to use it in the final model. We will have to tweak the model significantly.\n",
    "* Biggest problems currently facing: Tweaking the neural network, training data and minimizing loss.\n",
    "* We are on track to completing the project on time.\n",
    "* Yes it's worth proceeding with the project because we have enough diverse set of features to draw important conclusions affecting individual's (and families) work from home productivity in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wave 1 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_id</th>\n",
       "      <th>WFH_PRE</th>\n",
       "      <th>Job_Clerical or administrative support</th>\n",
       "      <th>Job_Manufacturing, construction, maintenance, or farming</th>\n",
       "      <th>Job_Professional, managerial, or technical</th>\n",
       "      <th>Job_Sales or service</th>\n",
       "      <th>Workload_increased</th>\n",
       "      <th>Workload_decreased</th>\n",
       "      <th>Increased_productivity</th>\n",
       "      <th>Decreased_productivity</th>\n",
       "      <th>hhveh_harm</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Number_bedrooms</th>\n",
       "      <th>Race_white</th>\n",
       "      <th>Gradutae_degree</th>\n",
       "      <th>High_income(LessThan_100K)</th>\n",
       "      <th>More_income(LMoreThan_35K)</th>\n",
       "      <th>ProEnvironment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>3714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>3730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>3733</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>3738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     resp_id  WFH_PRE  Job_Clerical or administrative support  \\\n",
       "0         11        0                                       0   \n",
       "1         29        1                                       0   \n",
       "2         30        0                                       0   \n",
       "3         31        1                                       0   \n",
       "4         34        1                                       0   \n",
       "..       ...      ...                                     ...   \n",
       "816     3710        1                                       0   \n",
       "817     3714        0                                       1   \n",
       "818     3730        0                                       0   \n",
       "819     3733        1                                       0   \n",
       "820     3738        1                                       1   \n",
       "\n",
       "     Job_Manufacturing, construction, maintenance, or farming  \\\n",
       "0                                                    0          \n",
       "1                                                    0          \n",
       "2                                                    0          \n",
       "3                                                    0          \n",
       "4                                                    0          \n",
       "..                                                 ...          \n",
       "816                                                  0          \n",
       "817                                                  0          \n",
       "818                                                  1          \n",
       "819                                                  0          \n",
       "820                                                  0          \n",
       "\n",
       "     Job_Professional, managerial, or technical  Job_Sales or service  \\\n",
       "0                                             0                     0   \n",
       "1                                             1                     0   \n",
       "2                                             1                     0   \n",
       "3                                             1                     0   \n",
       "4                                             1                     0   \n",
       "..                                          ...                   ...   \n",
       "816                                           0                     1   \n",
       "817                                           0                     0   \n",
       "818                                           0                     0   \n",
       "819                                           1                     0   \n",
       "820                                           0                     0   \n",
       "\n",
       "     Workload_increased  Workload_decreased  Increased_productivity  \\\n",
       "0                     1                   0                       1   \n",
       "1                     0                   0                       0   \n",
       "2                     0                   0                       0   \n",
       "3                     0                   0                       0   \n",
       "4                     0                   1                       0   \n",
       "..                  ...                 ...                     ...   \n",
       "816                   0                   0                       0   \n",
       "817                   0                   0                       0   \n",
       "818                   0                   1                       0   \n",
       "819                   0                   0                       0   \n",
       "820                   1                   0                       1   \n",
       "\n",
       "     Decreased_productivity  hhveh_harm  age  gender  Number_bedrooms  \\\n",
       "0                         0           2   44       1                5   \n",
       "1                         1           1   39       1                2   \n",
       "2                         1           4   49       0                4   \n",
       "3                         1           1   27       1                1   \n",
       "4                         0           0   32       0                5   \n",
       "..                      ...         ...  ...     ...              ...   \n",
       "816                       0           2   63       1                4   \n",
       "817                       0           1   62       1                3   \n",
       "818                       1           2   57       1                2   \n",
       "819                       0           2   34       0                3   \n",
       "820                       0           1   70       0                3   \n",
       "\n",
       "     Race_white  Gradutae_degree  High_income(LessThan_100K)  \\\n",
       "0             1                0                           0   \n",
       "1             1                1                           0   \n",
       "2             1                0                           0   \n",
       "3             1                1                           0   \n",
       "4             0                0                           0   \n",
       "..          ...              ...                         ...   \n",
       "816           1                1                           0   \n",
       "817           1                0                           0   \n",
       "818           1                0                           0   \n",
       "819           1                1                           0   \n",
       "820           1                0                           1   \n",
       "\n",
       "     More_income(LMoreThan_35K)  ProEnvironment  \n",
       "0                             0               1  \n",
       "1                             1               1  \n",
       "2                             1               1  \n",
       "3                             1               1  \n",
       "4                             0               1  \n",
       "..                          ...             ...  \n",
       "816                           1               1  \n",
       "817                           0               1  \n",
       "818                           0               1  \n",
       "819                           1               0  \n",
       "820                           0               1  \n",
       "\n",
       "[821 rows x 19 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave1 = pd.read_csv(\"Wave1_train.csv\")      # All Data\n",
    "\n",
    "wave1_train = wave1.iloc[:821,:]            # Training Data\n",
    "wave1_validation = wave1.iloc[821:,:]       # Validation Data\n",
    "\n",
    "wave1_test = pd.read_csv(\"Wave1_test.csv\")  # Test Data\n",
    "wave1_train.columns = wave1_train.columns.to_series().apply(lambda x: x.strip())\n",
    "wave1_train.shape, wave1_validation.shape\n",
    "wave1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the simplest possible neural network. It has 1 layer, that layer has 1 neuron, and the input is just 1 value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Job Type Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_36 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_37 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_38 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_39 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_40 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 5)            0           ['input_36[0][0]',               \n",
      "                                                                  'input_37[0][0]',               \n",
      "                                                                  'input_38[0][0]',               \n",
      "                                                                  'input_39[0][0]',               \n",
      "                                                                  'input_40[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 5)            30          ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1)            6           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(1,))\n",
    "input2 = tf.keras.layers.Input(shape=(1,))\n",
    "input3 = tf.keras.layers.Input(shape=(1,))\n",
    "input4 = tf.keras.layers.Input(shape=(1,))\n",
    "input5 = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([input1, input2, input3, input4, input5])\n",
    "dense1 = tf.keras.layers.Dense(5, input_dim=1, activation=tf.keras.activations.sigmoid, use_bias=True)(merged)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.keras.activations.relu, use_bias=True)(dense1)\n",
    "age_job_category_model = tf.keras.models.Model([input1, input2, input3, input4, input5], output)\n",
    "age_job_category_model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
    "age_job_category_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.5116 - val_loss: 0.3971 - val_accuracy: 0.6029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x296958880>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data\n",
    "input1 = wave1_train.loc[:,['age']]\n",
    "input2 = wave1_train.loc[:,['Job_Clerical or administrative support']]\n",
    "input3 = wave1_train.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "input4 = wave1_train.loc[:,['Job_Professional, managerial, or technical']]\n",
    "input5 = wave1_train.loc[:,['Job_Sales or service']]\n",
    "\n",
    "input1 = np.asarray(input1).astype('float32')\n",
    "input2 = np.asarray(input2).astype('float32')\n",
    "input3 = np.asarray(input3).astype('float32')\n",
    "input4 = np.asarray(input4).astype('float32')\n",
    "input5 = np.asarray(input5).astype('float32')\n",
    "\n",
    "y = wave1_train.loc[:,['WFH_PRE']]\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "# Validation data\n",
    "v_input1 = wave1_validation.loc[:,['age']]\n",
    "v_input2 = wave1_validation.loc[:,['Job_Clerical or administrative support']]\n",
    "v_input3 = wave1_validation.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "v_input4 = wave1_validation.loc[:,['Job_Professional, managerial, or technical']]\n",
    "v_input5 = wave1_validation.loc[:,['Job_Sales or service']]\n",
    "\n",
    "v_input1 = np.asarray(v_input1).astype('float32')\n",
    "v_input2 = np.asarray(v_input2).astype('float32')\n",
    "v_input3 = np.asarray(v_input3).astype('float32')\n",
    "v_input4 = np.asarray(v_input4).astype('float32')\n",
    "v_input5 = np.asarray(v_input5).astype('float32')\n",
    "\n",
    "v_y = wave1_validation.loc[:,['WFH_PRE']]\n",
    "v_y = np.asarray(v_y).astype('float32')\n",
    "\n",
    "age_job_category_model.fit([input1, input2, input3, input4, input5],y, \n",
    "                        batch_size=36, epochs=100, validation_data=([v_input1, v_input2, v_input3, v_input4, v_input5], v_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "t_input1 = wave1_test.loc[:,['age']]\n",
    "t_input2 = wave1_test.loc[:,['Job_Clerical or administrative support']]\n",
    "t_input3 = wave1_test.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "t_input4 = wave1_test.loc[:,['Job_Professional, managerial, or technical']]\n",
    "t_input5 = wave1_test.loc[:,['Job_Sales or service']]\n",
    "\n",
    "t_input1 = np.asarray(t_input1).astype('float32')\n",
    "t_input2 = np.asarray(t_input2).astype('float32')\n",
    "t_input3 = np.asarray(t_input3).astype('float32')\n",
    "t_input4 = np.asarray(t_input4).astype('float32')\n",
    "t_input5 = np.asarray(t_input5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49092886],\n",
       "       [0.48997596],\n",
       "       [0.49107453],\n",
       "       [0.48268172],\n",
       "       [0.48730424],\n",
       "       [0.48997596],\n",
       "       [0.4777086 ],\n",
       "       [0.49102786],\n",
       "       [0.49134395],\n",
       "       [0.49127498],\n",
       "       [0.49121407],\n",
       "       [0.49127498],\n",
       "       [0.49105105],\n",
       "       [0.49133167],\n",
       "       [0.49066594],\n",
       "       [0.49107453],\n",
       "       [0.48609582],\n",
       "       [0.4900615 ],\n",
       "       [0.49136767],\n",
       "       [0.49134395],\n",
       "       [0.49121407],\n",
       "       [0.48879763],\n",
       "       [0.49107453],\n",
       "       [0.4858593 ],\n",
       "       [0.49128994],\n",
       "       [0.4913027 ],\n",
       "       [0.48730424],\n",
       "       [0.48663548],\n",
       "       [0.4894394 ],\n",
       "       [0.4911867 ],\n",
       "       [0.48853442],\n",
       "       [0.48997596],\n",
       "       [0.4912577 ],\n",
       "       [0.49131367],\n",
       "       [0.4897448 ],\n",
       "       [0.49107453],\n",
       "       [0.49136326],\n",
       "       [0.4910241 ],\n",
       "       [0.48465696],\n",
       "       [0.49061707],\n",
       "       [0.4908177 ],\n",
       "       [0.49115488],\n",
       "       [0.48947564],\n",
       "       [0.4911867 ],\n",
       "       [0.49132302],\n",
       "       [0.4858578 ],\n",
       "       [0.49034497],\n",
       "       [0.49128994],\n",
       "       [0.49131367],\n",
       "       [0.48126373],\n",
       "       [0.48837307],\n",
       "       [0.48787907],\n",
       "       [0.49136767],\n",
       "       [0.49115488],\n",
       "       [0.48837307],\n",
       "       [0.4815168 ],\n",
       "       [0.4911867 ],\n",
       "       [0.48520717],\n",
       "       [0.47878   ],\n",
       "       [0.49111775],\n",
       "       [0.49018463],\n",
       "       [0.49133798],\n",
       "       [0.49024907],\n",
       "       [0.49034497],\n",
       "       [0.49130347],\n",
       "       [0.48053542],\n",
       "       [0.4910241 ],\n",
       "       [0.4777086 ],\n",
       "       [0.49061707],\n",
       "       [0.49133798],\n",
       "       [0.4875042 ],\n",
       "       [0.48495367],\n",
       "       [0.49017444],\n",
       "       [0.48947564],\n",
       "       [0.49111775],\n",
       "       [0.48390272],\n",
       "       [0.49113533],\n",
       "       [0.49096557],\n",
       "       [0.49017444],\n",
       "       [0.48351333],\n",
       "       [0.49133798],\n",
       "       [0.4909928 ],\n",
       "       [0.48390272],\n",
       "       [0.47549534],\n",
       "       [0.48663548],\n",
       "       [0.49134895],\n",
       "       [0.49121585],\n",
       "       [0.4908177 ],\n",
       "       [0.49061707],\n",
       "       [0.49133798],\n",
       "       [0.48609582],\n",
       "       [0.48787907],\n",
       "       [0.49133107],\n",
       "       [0.47293127],\n",
       "       [0.49132302],\n",
       "       [0.49076733],\n",
       "       [0.49034497],\n",
       "       [0.49121407],\n",
       "       [0.47961792],\n",
       "       [0.48390272],\n",
       "       [0.49096557],\n",
       "       [0.49134907],\n",
       "       [0.49121407],\n",
       "       [0.49115488],\n",
       "       [0.47549534],\n",
       "       [0.49136564],\n",
       "       [0.48997596],\n",
       "       [0.49035403],\n",
       "       [0.490725  ],\n",
       "       [0.48894092],\n",
       "       [0.49034497],\n",
       "       [0.48685518],\n",
       "       [0.49121407],\n",
       "       [0.48609582],\n",
       "       [0.48268172],\n",
       "       [0.48390272],\n",
       "       [0.4858578 ],\n",
       "       [0.48837307],\n",
       "       [0.49096557],\n",
       "       [0.48268172],\n",
       "       [0.49049136],\n",
       "       [0.49107453],\n",
       "       [0.49017444],\n",
       "       [0.48997596],\n",
       "       [0.49131367],\n",
       "       [0.4908177 ],\n",
       "       [0.49049136],\n",
       "       [0.48663548],\n",
       "       [0.48390272],\n",
       "       [0.48730424],\n",
       "       [0.49061707],\n",
       "       [0.4908972 ],\n",
       "       [0.48268172],\n",
       "       [0.47554854],\n",
       "       [0.49136183],\n",
       "       [0.49017444],\n",
       "       [0.4777086 ],\n",
       "       [0.4849452 ],\n",
       "       [0.48730424],\n",
       "       [0.48805943],\n",
       "       [0.4910777 ],\n",
       "       [0.4778668 ],\n",
       "       [0.4728197 ],\n",
       "       [0.49061707],\n",
       "       [0.49131814],\n",
       "       [0.49090204],\n",
       "       [0.4909928 ],\n",
       "       [0.48126373],\n",
       "       [0.47549534],\n",
       "       [0.48997596],\n",
       "       [0.48805943],\n",
       "       [0.48787907],\n",
       "       [0.48495367],\n",
       "       [0.48916236],\n",
       "       [0.4911867 ],\n",
       "       [0.49128994],\n",
       "       [0.490725  ],\n",
       "       [0.48837307],\n",
       "       [0.490725  ],\n",
       "       [0.49017444],\n",
       "       [0.48947564],\n",
       "       [0.49115726],\n",
       "       [0.48390272],\n",
       "       [0.48805943],\n",
       "       [0.48787907],\n",
       "       [0.48730424],\n",
       "       [0.4913344 ],\n",
       "       [0.4858578 ],\n",
       "       [0.49125907],\n",
       "       [0.4897448 ],\n",
       "       [0.49133107],\n",
       "       [0.49134395],\n",
       "       [0.49061707],\n",
       "       [0.49017444],\n",
       "       [0.48879763],\n",
       "       [0.49123755],\n",
       "       [0.48916236],\n",
       "       [0.4777086 ],\n",
       "       [0.49017444],\n",
       "       [0.48997596],\n",
       "       [0.49128994],\n",
       "       [0.47549534],\n",
       "       [0.47522599],\n",
       "       [0.49117187],\n",
       "       [0.49134395],\n",
       "       [0.49128994],\n",
       "       [0.49127498],\n",
       "       [0.47549534],\n",
       "       [0.4841664 ],\n",
       "       [0.49127498],\n",
       "       [0.49128994],\n",
       "       [0.49132302],\n",
       "       [0.48495367],\n",
       "       [0.48390272],\n",
       "       [0.49134395],\n",
       "       [0.490725  ],\n",
       "       [0.48495367],\n",
       "       [0.48730424],\n",
       "       [0.48787907],\n",
       "       [0.49111775],\n",
       "       [0.49017444],\n",
       "       [0.48997596],\n",
       "       [0.48879763],\n",
       "       [0.4913694 ],\n",
       "       [0.49128994],\n",
       "       [0.49111775],\n",
       "       [0.48730424],\n",
       "       [0.48126373],\n",
       "       [0.4910241 ],\n",
       "       [0.48879763],\n",
       "       [0.48263654],\n",
       "       [0.48495367],\n",
       "       [0.48916236],\n",
       "       [0.4777086 ],\n",
       "       [0.49017444],\n",
       "       [0.4841664 ],\n",
       "       [0.48390272],\n",
       "       [0.48664334],\n",
       "       [0.49104777],\n",
       "       [0.49132684],\n",
       "       [0.48731586],\n",
       "       [0.48685518],\n",
       "       [0.49133107],\n",
       "       [0.48663548],\n",
       "       [0.49111775],\n",
       "       [0.48997596],\n",
       "       [0.46575886],\n",
       "       [0.48663548],\n",
       "       [0.49128994],\n",
       "       [0.49136326],\n",
       "       [0.49121585],\n",
       "       [0.48495367],\n",
       "       [0.48730424],\n",
       "       [0.48663548],\n",
       "       [0.48663548],\n",
       "       [0.48520717],\n",
       "       [0.4913694 ],\n",
       "       [0.4911867 ],\n",
       "       [0.49135718],\n",
       "       [0.49134907],\n",
       "       [0.48390272],\n",
       "       [0.49104777],\n",
       "       [0.48916236],\n",
       "       [0.49121407],\n",
       "       [0.4858578 ],\n",
       "       [0.49128994],\n",
       "       [0.49127498],\n",
       "       [0.49133798],\n",
       "       [0.49049136],\n",
       "       [0.49134895],\n",
       "       [0.49034497],\n",
       "       [0.48879763],\n",
       "       [0.49115488],\n",
       "       [0.48916236],\n",
       "       [0.48268172],\n",
       "       [0.4908972 ],\n",
       "       [0.48787907],\n",
       "       [0.49034497],\n",
       "       [0.49049136],\n",
       "       [0.48916236],\n",
       "       [0.4811873 ],\n",
       "       [0.49107453],\n",
       "       [0.48663548],\n",
       "       [0.49128994],\n",
       "       [0.4913027 ],\n",
       "       [0.48947564],\n",
       "       [0.49111775],\n",
       "       [0.4858578 ],\n",
       "       [0.49096557],\n",
       "       [0.49107453],\n",
       "       [0.4909698 ],\n",
       "       [0.49096557],\n",
       "       [0.48495367],\n",
       "       [0.4911867 ],\n",
       "       [0.48916236],\n",
       "       [0.4913027 ],\n",
       "       [0.48390272],\n",
       "       [0.48495367],\n",
       "       [0.48126373],\n",
       "       [0.48663548],\n",
       "       [0.48663548],\n",
       "       [0.48837307],\n",
       "       [0.48879763],\n",
       "       [0.48916236],\n",
       "       [0.48685518],\n",
       "       [0.48730424],\n",
       "       [0.4912577 ],\n",
       "       [0.4913027 ],\n",
       "       [0.48947564],\n",
       "       [0.4858578 ],\n",
       "       [0.4858578 ],\n",
       "       [0.48916236],\n",
       "       [0.4849452 ],\n",
       "       [0.48730424],\n",
       "       [0.48787907],\n",
       "       [0.4913344 ],\n",
       "       [0.47752562],\n",
       "       [0.49112055],\n",
       "       [0.48787907]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "age_job_category_model.predict([t_input1, t_input2, t_input3, t_input4, t_input5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree or Pro Environment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_41 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_42 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_43 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_44 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_45 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 5)            0           ['input_41[0][0]',               \n",
      "                                                                  'input_42[0][0]',               \n",
      "                                                                  'input_43[0][0]',               \n",
      "                                                                  'input_44[0][0]',               \n",
      "                                                                  'input_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 5)            30          ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1)            6           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(1,))\n",
    "input2 = tf.keras.layers.Input(shape=(1,))\n",
    "input3 = tf.keras.layers.Input(shape=(1,))\n",
    "input4 = tf.keras.layers.Input(shape=(1,))\n",
    "input5 = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([input1, input2, input3, input4, input5])\n",
    "dense1 = tf.keras.layers.Dense(5, input_dim=1, activation=tf.keras.activations.sigmoid, use_bias=True)(merged)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.keras.activations.relu, use_bias=True)(dense1)\n",
    "degree_environment_model = tf.keras.models.Model([input1, input2, input3, input4, input5], output)\n",
    "degree_environment_model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
    "degree_environment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2732 - accuracy: 0.5116 - val_loss: 0.2408 - val_accuracy: 0.6029\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.5116 - val_loss: 0.2452 - val_accuracy: 0.6029\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.5104 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5104 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5128 - val_loss: 0.2480 - val_accuracy: 0.6017\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5104 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5079 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5116 - val_loss: 0.2501 - val_accuracy: 0.5384\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5055 - val_loss: 0.2487 - val_accuracy: 0.5981\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5091 - val_loss: 0.2490 - val_accuracy: 0.5932\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4872 - val_loss: 0.2475 - val_accuracy: 0.6029\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5116 - val_loss: 0.2471 - val_accuracy: 0.6029\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5018 - val_loss: 0.2461 - val_accuracy: 0.6029\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5104 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2495 - val_accuracy: 0.5847\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4994 - val_loss: 0.2488 - val_accuracy: 0.5981\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2493 - val_accuracy: 0.5920\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5030 - val_loss: 0.2493 - val_accuracy: 0.5920\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4970 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4994 - val_loss: 0.2481 - val_accuracy: 0.6017\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4909 - val_loss: 0.2471 - val_accuracy: 0.6029\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5104 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2497 - val_accuracy: 0.5773\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4799 - val_loss: 0.2475 - val_accuracy: 0.6029\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5043 - val_loss: 0.2464 - val_accuracy: 0.6029\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4921 - val_loss: 0.2462 - val_accuracy: 0.6029\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5079 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5006 - val_loss: 0.2475 - val_accuracy: 0.6029\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4982 - val_loss: 0.2470 - val_accuracy: 0.6029\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5128 - val_loss: 0.2473 - val_accuracy: 0.6029\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5104 - val_loss: 0.2492 - val_accuracy: 0.5907\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5055 - val_loss: 0.2483 - val_accuracy: 0.6017\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5091 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.4933 - val_loss: 0.2468 - val_accuracy: 0.6029\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5116 - val_loss: 0.2492 - val_accuracy: 0.5944\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4909 - val_loss: 0.2473 - val_accuracy: 0.6029\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.5030 - val_loss: 0.2464 - val_accuracy: 0.6029\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5067 - val_loss: 0.2460 - val_accuracy: 0.6029\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5128 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.5128 - val_loss: 0.2502 - val_accuracy: 0.3971\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4994 - val_loss: 0.2495 - val_accuracy: 0.5907\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4933 - val_loss: 0.2488 - val_accuracy: 0.5993\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4884 - val_loss: 0.2477 - val_accuracy: 0.6029\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5104 - val_loss: 0.2480 - val_accuracy: 0.6029\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.4945 - val_loss: 0.2463 - val_accuracy: 0.6029\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5067 - val_loss: 0.2470 - val_accuracy: 0.6029\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5091 - val_loss: 0.2477 - val_accuracy: 0.6029\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4921 - val_loss: 0.2468 - val_accuracy: 0.6029\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.5104 - val_loss: 0.2484 - val_accuracy: 0.6017\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5055 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4982 - val_loss: 0.2464 - val_accuracy: 0.6029\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5091 - val_loss: 0.2470 - val_accuracy: 0.6029\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.4994 - val_loss: 0.2478 - val_accuracy: 0.6029\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5116 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5116 - val_loss: 0.2494 - val_accuracy: 0.5932\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4970 - val_loss: 0.2493 - val_accuracy: 0.5920\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5104 - val_loss: 0.2482 - val_accuracy: 0.6029\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4982 - val_loss: 0.2470 - val_accuracy: 0.6029\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4823 - val_loss: 0.2458 - val_accuracy: 0.6029\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5116 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4994 - val_loss: 0.2472 - val_accuracy: 0.6029\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2482 - val_accuracy: 0.6029\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4982 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4921 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5067 - val_loss: 0.2465 - val_accuracy: 0.6029\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5128 - val_loss: 0.2475 - val_accuracy: 0.6029\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.4994 - val_loss: 0.2461 - val_accuracy: 0.6029\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2485 - val_accuracy: 0.6017\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5116 - val_loss: 0.2488 - val_accuracy: 0.6029\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5043 - val_loss: 0.2471 - val_accuracy: 0.6029\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4994 - val_loss: 0.2474 - val_accuracy: 0.6029\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4933 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.5116 - val_loss: 0.2489 - val_accuracy: 0.5981\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.4799 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5030 - val_loss: 0.2469 - val_accuracy: 0.6029\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5043 - val_loss: 0.2473 - val_accuracy: 0.6029\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5030 - val_loss: 0.2468 - val_accuracy: 0.6029\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5079 - val_loss: 0.2459 - val_accuracy: 0.6029\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5104 - val_loss: 0.2461 - val_accuracy: 0.6029\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2485 - val_accuracy: 0.6029\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5091 - val_loss: 0.2482 - val_accuracy: 0.6029\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5152 - val_loss: 0.2498 - val_accuracy: 0.5761\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5043 - val_loss: 0.2491 - val_accuracy: 0.5993\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.4872 - val_loss: 0.2481 - val_accuracy: 0.6029\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5006 - val_loss: 0.2474 - val_accuracy: 0.6029\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4957 - val_loss: 0.2473 - val_accuracy: 0.6029\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.5104 - val_loss: 0.2495 - val_accuracy: 0.5907\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.4982 - val_loss: 0.2496 - val_accuracy: 0.5847\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4909 - val_loss: 0.2493 - val_accuracy: 0.5944\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.4714 - val_loss: 0.2473 - val_accuracy: 0.6029\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5043 - val_loss: 0.2476 - val_accuracy: 0.6029\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.5104 - val_loss: 0.2484 - val_accuracy: 0.6029\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.5006 - val_loss: 0.2479 - val_accuracy: 0.6029\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.5116 - val_loss: 0.2484 - val_accuracy: 0.6029\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.5079 - val_loss: 0.2465 - val_accuracy: 0.6029\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5043 - val_loss: 0.2469 - val_accuracy: 0.6029\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.5104 - val_loss: 0.2490 - val_accuracy: 0.6017\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.5091 - val_loss: 0.2504 - val_accuracy: 0.3971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x299cba970>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data\n",
    "input1 = wave1_train.loc[:,['age']]\n",
    "input2 = wave1_train.loc[:,['Workload_increased']]\n",
    "input3 = wave1_train.loc[:,['Workload_decreased']]\n",
    "input4 = wave1_train.loc[:,['Gradutae_degree']]\n",
    "input5 = wave1_train.loc[:,['ProEnvironment']]\n",
    "\n",
    "input1 = np.asarray(input1).astype('float32')\n",
    "input2 = np.asarray(input2).astype('float32')\n",
    "input3 = np.asarray(input3).astype('float32')\n",
    "input4 = np.asarray(input4).astype('float32')\n",
    "input5 = np.asarray(input5).astype('float32')\n",
    "\n",
    "y = wave1_train.loc[:,['WFH_PRE']]\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "# Validation Data\n",
    "v_input1 = wave1_validation.loc[:,['age']]\n",
    "v_input2 = wave1_validation.loc[:,['Workload_increased']]\n",
    "v_input3 = wave1_validation.loc[:,['Workload_decreased']]\n",
    "v_input4 = wave1_validation.loc[:,['Gradutae_degree']]\n",
    "v_input5 = wave1_validation.loc[:,['ProEnvironment']]\n",
    "\n",
    "v_input1 = np.asarray(v_input1).astype('float32')\n",
    "v_input2 = np.asarray(v_input2).astype('float32')\n",
    "v_input3 = np.asarray(v_input3).astype('float32')\n",
    "v_input4 = np.asarray(v_input4).astype('float32')\n",
    "v_input5 = np.asarray(v_input5).astype('float32')\n",
    "\n",
    "v_y = wave1_validation.loc[:,['WFH_PRE']]\n",
    "v_y = np.asarray(v_y).astype('float32')\n",
    "\n",
    "degree_environment_model.fit([input1, input2, input3, input4, input5],y, batch_size=36, epochs=100, \n",
    "                        validation_data=([v_input1, v_input2, v_input3, v_input4, v_input5], v_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "t_input1 = wave1_test.loc[:,['age']]\n",
    "t_input2 = wave1_test.loc[:,['Workload_increased']]\n",
    "t_input3 = wave1_test.loc[:,['Workload_decreased']]\n",
    "t_input4 = wave1_test.loc[:,['Gradutae_degree']]\n",
    "t_input5 = wave1_test.loc[:,['ProEnvironment']]\n",
    "\n",
    "t_input1 = np.asarray(t_input1).astype('float32')\n",
    "t_input2 = np.asarray(t_input2).astype('float32')\n",
    "t_input3 = np.asarray(t_input3).astype('float32')\n",
    "t_input4 = np.asarray(t_input4).astype('float32')\n",
    "t_input5 = np.asarray(t_input5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 628us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48788524],\n",
       "       [0.487656  ],\n",
       "       [0.4879204 ],\n",
       "       [0.48520166],\n",
       "       [0.48683208],\n",
       "       [0.487656  ],\n",
       "       [0.48335648],\n",
       "       [0.48789835],\n",
       "       [0.48796362],\n",
       "       [0.48795462],\n",
       "       [0.4879452 ],\n",
       "       [0.48795462],\n",
       "       [0.48795402],\n",
       "       [0.4879613 ],\n",
       "       [0.48782486],\n",
       "       [0.4879204 ],\n",
       "       [0.48660904],\n",
       "       [0.48767382],\n",
       "       [0.48796582],\n",
       "       [0.48796362],\n",
       "       [0.4879452 ],\n",
       "       [0.48731196],\n",
       "       [0.4879204 ],\n",
       "       [0.48579633],\n",
       "       [0.48795676],\n",
       "       [0.48795855],\n",
       "       [0.48683208],\n",
       "       [0.48660684],\n",
       "       [0.48740232],\n",
       "       [0.48794067],\n",
       "       [0.48726445],\n",
       "       [0.487656  ],\n",
       "       [0.4879521 ],\n",
       "       [0.48795992],\n",
       "       [0.48759186],\n",
       "       [0.4879204 ],\n",
       "       [0.48796546],\n",
       "       [0.4879105 ],\n",
       "       [0.4857415 ],\n",
       "       [0.48782074],\n",
       "       [0.487867  ],\n",
       "       [0.48793507],\n",
       "       [0.48751497],\n",
       "       [0.48794067],\n",
       "       [0.48796117],\n",
       "       [0.48633897],\n",
       "       [0.4877534 ],\n",
       "       [0.48795676],\n",
       "       [0.48795992],\n",
       "       [0.48468006],\n",
       "       [0.4871794 ],\n",
       "       [0.4870211 ],\n",
       "       [0.48796582],\n",
       "       [0.48793507],\n",
       "       [0.4871794 ],\n",
       "       [0.48549992],\n",
       "       [0.48794067],\n",
       "       [0.48637903],\n",
       "       [0.48829263],\n",
       "       [0.4879284 ],\n",
       "       [0.4876445 ],\n",
       "       [0.4879629 ],\n",
       "       [0.48772192],\n",
       "       [0.4877534 ],\n",
       "       [0.48795694],\n",
       "       [0.4881299 ],\n",
       "       [0.4879105 ],\n",
       "       [0.48335648],\n",
       "       [0.48782074],\n",
       "       [0.4879629 ],\n",
       "       [0.48698455],\n",
       "       [0.48602128],\n",
       "       [0.48770922],\n",
       "       [0.48751497],\n",
       "       [0.4879284 ],\n",
       "       [0.4856453 ],\n",
       "       [0.48792815],\n",
       "       [0.4878986 ],\n",
       "       [0.48770922],\n",
       "       [0.48535657],\n",
       "       [0.4879629 ],\n",
       "       [0.48789912],\n",
       "       [0.4856453 ],\n",
       "       [0.48253024],\n",
       "       [0.48660684],\n",
       "       [0.4879632 ],\n",
       "       [0.4879409 ],\n",
       "       [0.487867  ],\n",
       "       [0.48782074],\n",
       "       [0.4879629 ],\n",
       "       [0.48660904],\n",
       "       [0.4870211 ],\n",
       "       [0.48796213],\n",
       "       [0.48157817],\n",
       "       [0.48796117],\n",
       "       [0.48784876],\n",
       "       [0.4877534 ],\n",
       "       [0.4879452 ],\n",
       "       [0.48406905],\n",
       "       [0.4856453 ],\n",
       "       [0.4878986 ],\n",
       "       [0.48796415],\n",
       "       [0.4879452 ],\n",
       "       [0.48793507],\n",
       "       [0.48253024],\n",
       "       [0.48796564],\n",
       "       [0.487656  ],\n",
       "       [0.48770106],\n",
       "       [0.48784602],\n",
       "       [0.48737496],\n",
       "       [0.4877534 ],\n",
       "       [0.4868101 ],\n",
       "       [0.4879452 ],\n",
       "       [0.48660904],\n",
       "       [0.48520166],\n",
       "       [0.4856453 ],\n",
       "       [0.48633897],\n",
       "       [0.4871794 ],\n",
       "       [0.4878986 ],\n",
       "       [0.48520166],\n",
       "       [0.48779023],\n",
       "       [0.4879204 ],\n",
       "       [0.48770922],\n",
       "       [0.487656  ],\n",
       "       [0.48795992],\n",
       "       [0.487867  ],\n",
       "       [0.48779023],\n",
       "       [0.48660684],\n",
       "       [0.4856453 ],\n",
       "       [0.48683208],\n",
       "       [0.48782074],\n",
       "       [0.48788428],\n",
       "       [0.48520166],\n",
       "       [0.48437595],\n",
       "       [0.48796523],\n",
       "       [0.48770922],\n",
       "       [0.48335648],\n",
       "       [0.48534822],\n",
       "       [0.48683208],\n",
       "       [0.48713517],\n",
       "       [0.4879104 ],\n",
       "       [0.48476732],\n",
       "       [0.48398876],\n",
       "       [0.48782074],\n",
       "       [0.48795974],\n",
       "       [0.4878658 ],\n",
       "       [0.48789912],\n",
       "       [0.48468006],\n",
       "       [0.48253024],\n",
       "       [0.487656  ],\n",
       "       [0.48713517],\n",
       "       [0.4870211 ],\n",
       "       [0.48602128],\n",
       "       [0.4874226 ],\n",
       "       [0.48794067],\n",
       "       [0.48795676],\n",
       "       [0.48784602],\n",
       "       [0.4871794 ],\n",
       "       [0.48784602],\n",
       "       [0.48770922],\n",
       "       [0.48751497],\n",
       "       [0.48792863],\n",
       "       [0.4856453 ],\n",
       "       [0.48713517],\n",
       "       [0.4870211 ],\n",
       "       [0.48683208],\n",
       "       [0.48796195],\n",
       "       [0.48633897],\n",
       "       [0.4879492 ],\n",
       "       [0.48759186],\n",
       "       [0.48796213],\n",
       "       [0.48796362],\n",
       "       [0.48782074],\n",
       "       [0.48770922],\n",
       "       [0.48731196],\n",
       "       [0.487949  ],\n",
       "       [0.4874226 ],\n",
       "       [0.48335648],\n",
       "       [0.48770922],\n",
       "       [0.487656  ],\n",
       "       [0.48795676],\n",
       "       [0.48253024],\n",
       "       [0.4800644 ],\n",
       "       [0.48795915],\n",
       "       [0.48796362],\n",
       "       [0.48795676],\n",
       "       [0.48795462],\n",
       "       [0.48253024],\n",
       "       [0.48611802],\n",
       "       [0.48795462],\n",
       "       [0.48795676],\n",
       "       [0.48796117],\n",
       "       [0.48602128],\n",
       "       [0.4856453 ],\n",
       "       [0.48796362],\n",
       "       [0.48784602],\n",
       "       [0.48602128],\n",
       "       [0.48683208],\n",
       "       [0.4870211 ],\n",
       "       [0.4879284 ],\n",
       "       [0.48770922],\n",
       "       [0.487656  ],\n",
       "       [0.48731196],\n",
       "       [0.487966  ],\n",
       "       [0.48795676],\n",
       "       [0.4879284 ],\n",
       "       [0.48683208],\n",
       "       [0.48468006],\n",
       "       [0.4879105 ],\n",
       "       [0.48731196],\n",
       "       [0.4841652 ],\n",
       "       [0.48602128],\n",
       "       [0.4874226 ],\n",
       "       [0.48335648],\n",
       "       [0.48770922],\n",
       "       [0.48611802],\n",
       "       [0.4856453 ],\n",
       "       [0.48616904],\n",
       "       [0.48791063],\n",
       "       [0.48796093],\n",
       "       [0.4864787 ],\n",
       "       [0.4868101 ],\n",
       "       [0.48796213],\n",
       "       [0.48660684],\n",
       "       [0.4879284 ],\n",
       "       [0.487656  ],\n",
       "       [0.47453487],\n",
       "       [0.48660684],\n",
       "       [0.48795676],\n",
       "       [0.48796546],\n",
       "       [0.4879409 ],\n",
       "       [0.48602128],\n",
       "       [0.48683208],\n",
       "       [0.48660684],\n",
       "       [0.48660684],\n",
       "       [0.48637903],\n",
       "       [0.487966  ],\n",
       "       [0.48794067],\n",
       "       [0.487965  ],\n",
       "       [0.48796415],\n",
       "       [0.4856453 ],\n",
       "       [0.48791063],\n",
       "       [0.4874226 ],\n",
       "       [0.4879452 ],\n",
       "       [0.48633897],\n",
       "       [0.48795676],\n",
       "       [0.48795462],\n",
       "       [0.4879629 ],\n",
       "       [0.48779023],\n",
       "       [0.4879632 ],\n",
       "       [0.4877534 ],\n",
       "       [0.48731196],\n",
       "       [0.48793507],\n",
       "       [0.4874226 ],\n",
       "       [0.48520166],\n",
       "       [0.48788428],\n",
       "       [0.4870211 ],\n",
       "       [0.4877534 ],\n",
       "       [0.48779023],\n",
       "       [0.4874226 ],\n",
       "       [0.4833932 ],\n",
       "       [0.4879204 ],\n",
       "       [0.48660684],\n",
       "       [0.48795676],\n",
       "       [0.48795855],\n",
       "       [0.48751497],\n",
       "       [0.4879284 ],\n",
       "       [0.48633897],\n",
       "       [0.4878986 ],\n",
       "       [0.4879204 ],\n",
       "       [0.48788363],\n",
       "       [0.4878986 ],\n",
       "       [0.48602128],\n",
       "       [0.48794067],\n",
       "       [0.4874226 ],\n",
       "       [0.48795855],\n",
       "       [0.4856453 ],\n",
       "       [0.48602128],\n",
       "       [0.48468006],\n",
       "       [0.48660684],\n",
       "       [0.48660684],\n",
       "       [0.4871794 ],\n",
       "       [0.48731196],\n",
       "       [0.4874226 ],\n",
       "       [0.4868101 ],\n",
       "       [0.48683208],\n",
       "       [0.4879521 ],\n",
       "       [0.48795855],\n",
       "       [0.48751497],\n",
       "       [0.48633897],\n",
       "       [0.48633897],\n",
       "       [0.4874226 ],\n",
       "       [0.48534822],\n",
       "       [0.48683208],\n",
       "       [0.4870211 ],\n",
       "       [0.48796195],\n",
       "       [0.4813714 ],\n",
       "       [0.4879204 ],\n",
       "       [0.4870211 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "degree_environment_model.predict([t_input1, t_input2, t_input3, t_input4, t_input5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wave 2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_id</th>\n",
       "      <th>wfh_expect</th>\n",
       "      <th>Job_Clerical or administrative support</th>\n",
       "      <th>Job_Manufacturing, construction, maintenance, or farming</th>\n",
       "      <th>Job_Professional, managerial, or technical</th>\n",
       "      <th>Job_Sales or service</th>\n",
       "      <th>Workload_increased</th>\n",
       "      <th>Workload_decreased</th>\n",
       "      <th>Increased_productivity</th>\n",
       "      <th>Decreased_productivity</th>\n",
       "      <th>hhveh_harm</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Number_bedrooms</th>\n",
       "      <th>Race_white</th>\n",
       "      <th>Gradutae_degree</th>\n",
       "      <th>High_income(LessThan_100K)</th>\n",
       "      <th>More_income(LMoreThan_35K)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1177</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1188</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1189</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1194</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1202</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>4593</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>4601</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>4613</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>4618</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>4622</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>684 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     resp_id wfh_expect  Job_Clerical or administrative support  \\\n",
       "0       1177        Yes                                       0   \n",
       "1       1188        Yes                                       0   \n",
       "2       1189        Yes                                       0   \n",
       "3       1194        Yes                                       0   \n",
       "4       1202        Yes                                       0   \n",
       "..       ...        ...                                     ...   \n",
       "679     4593         No                                       0   \n",
       "680     4601        Yes                                       0   \n",
       "681     4613        Yes                                       0   \n",
       "682     4618        Yes                                       0   \n",
       "683     4622         No                                       0   \n",
       "\n",
       "     Job_Manufacturing, construction, maintenance, or farming  \\\n",
       "0                                                    0          \n",
       "1                                                    0          \n",
       "2                                                    0          \n",
       "3                                                    0          \n",
       "4                                                    0          \n",
       "..                                                 ...          \n",
       "679                                                  0          \n",
       "680                                                  0          \n",
       "681                                                  0          \n",
       "682                                                  0          \n",
       "683                                                  0          \n",
       "\n",
       "     Job_Professional, managerial, or technical  Job_Sales or service  \\\n",
       "0                                             1                     0   \n",
       "1                                             1                     0   \n",
       "2                                             0                     0   \n",
       "3                                             1                     0   \n",
       "4                                             0                     0   \n",
       "..                                          ...                   ...   \n",
       "679                                           0                     1   \n",
       "680                                           1                     0   \n",
       "681                                           0                     1   \n",
       "682                                           1                     0   \n",
       "683                                           0                     0   \n",
       "\n",
       "     Workload_increased  Workload_decreased  Increased_productivity  \\\n",
       "0                     0                   0                       1   \n",
       "1                     0                   0                       1   \n",
       "2                     0                   0                       0   \n",
       "3                     0                   0                       0   \n",
       "4                     0                   0                       0   \n",
       "..                  ...                 ...                     ...   \n",
       "679                   0                   1                       0   \n",
       "680                   0                   0                       0   \n",
       "681                   1                   0                       1   \n",
       "682                   0                   1                       0   \n",
       "683                   0                   0                       0   \n",
       "\n",
       "     Decreased_productivity  hhveh_harm  age  gender  Number_bedrooms  \\\n",
       "0                         0           2   58       1                3   \n",
       "1                         0           1   66       0                2   \n",
       "2                         0           0   24       1                3   \n",
       "3                         0           1   31       1                3   \n",
       "4                         0           0   23       0                2   \n",
       "..                      ...         ...  ...     ...              ...   \n",
       "679                       1           4   59       0                3   \n",
       "680                       0           2   56       1                3   \n",
       "681                       0           2   66       0                4   \n",
       "682                       1           1   73       0                3   \n",
       "683                       0           2   53       1                3   \n",
       "\n",
       "     Race_white  Gradutae_degree  High_income(LessThan_100K)  \\\n",
       "0             0                1                           0   \n",
       "1             1                0                           0   \n",
       "2             1                0                           1   \n",
       "3             1                1                           0   \n",
       "4             0                1                           1   \n",
       "..          ...              ...                         ...   \n",
       "679           1                0                           0   \n",
       "680           1                0                           0   \n",
       "681           1                1                           0   \n",
       "682           1                1                           0   \n",
       "683           1                0                           1   \n",
       "\n",
       "     More_income(LMoreThan_35K)  \n",
       "0                             1  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             1  \n",
       "4                             0  \n",
       "..                          ...  \n",
       "679                           1  \n",
       "680                           0  \n",
       "681                           1  \n",
       "682                           0  \n",
       "683                           0  \n",
       "\n",
       "[684 rows x 18 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave2 = pd.read_csv(\"Wave2_train.csv\")      # All Data\n",
    "\n",
    "train = wave2.iloc[:684,:]            # Training Data\n",
    "validation = wave2.iloc[684:,:]       # Validation Data\n",
    "\n",
    "test = pd.read_csv(\"Wave2_test.csv\")  # Test Data\n",
    "train.columns = train.columns.to_series().apply(lambda x: x.strip())\n",
    "train.shape, validation.shape\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the simplest possible neural network. It has 1 layer, that layer has 1 neuron, and the input is just 1 value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Job Type Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_33 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 5)            0           ['input_31[0][0]',               \n",
      "                                                                  'input_32[0][0]',               \n",
      "                                                                  'input_33[0][0]',               \n",
      "                                                                  'input_34[0][0]',               \n",
      "                                                                  'input_35[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 5)            30          ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1)            6           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(1,))\n",
    "input2 = tf.keras.layers.Input(shape=(1,))\n",
    "input3 = tf.keras.layers.Input(shape=(1,))\n",
    "input4 = tf.keras.layers.Input(shape=(1,))\n",
    "input5 = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([input1, input2, input3, input4, input5])\n",
    "dense1 = tf.keras.layers.Dense(5, input_dim=1, activation=tf.keras.activations.sigmoid, use_bias=True)(merged)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.keras.activations.relu, use_bias=True)(dense1)\n",
    "age_job_category_model = tf.keras.models.Model([input1, input2, input3, input4, input5], output)\n",
    "age_job_category_model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "age_job_category_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [57], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m input5 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(input5)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m y \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mloc[:,[\u001b[39m'\u001b[39m\u001b[39mwfh_expect\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m---> 15\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(y)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Validation data\u001b[39;00m\n\u001b[1;32m     18\u001b[0m v_input1 \u001b[39m=\u001b[39m validation\u001b[39m.\u001b[39mloc[:,[\u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Yes'"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "input1 = train.loc[:,['age']]\n",
    "input2 = train.loc[:,['Job_Clerical or administrative support']]\n",
    "input3 = train.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "input4 = train.loc[:,['Job_Professional, managerial, or technical']]\n",
    "input5 = train.loc[:,['Job_Sales or service']]\n",
    "\n",
    "input1 = np.asarray(input1).astype('float32')\n",
    "input2 = np.asarray(input2).astype('float32')\n",
    "input3 = np.asarray(input3).astype('float32')\n",
    "input4 = np.asarray(input4).astype('float32')\n",
    "input5 = np.asarray(input5).astype('float32')\n",
    "\n",
    "y = train.loc[:,['wfh_expect']]\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "# Validation data\n",
    "v_input1 = validation.loc[:,['age']]\n",
    "v_input2 = validation.loc[:,['Job_Clerical or administrative support']]\n",
    "v_input3 = validation.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "v_input4 = validation.loc[:,['Job_Professional, managerial, or technical']]\n",
    "v_input5 = validation.loc[:,['Job_Sales or service']]\n",
    "\n",
    "v_input1 = np.asarray(v_input1).astype('float32')\n",
    "v_input2 = np.asarray(v_input2).astype('float32')\n",
    "v_input3 = np.asarray(v_input3).astype('float32')\n",
    "v_input4 = np.asarray(v_input4).astype('float32')\n",
    "v_input5 = np.asarray(v_input5).astype('float32')\n",
    "\n",
    "v_y = validation.loc[:,['wfh_expect']]\n",
    "v_y = np.asarray(v_y).astype('float32')\n",
    "\n",
    "age_job_category_model.fit([input1, input2, input3, input4, input5],y, \n",
    "                        batch_size=36, epochs=100, validation_data=([v_input1, v_input2, v_input3, v_input4, v_input5], v_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "t_input1 = test.loc[:,['age']]\n",
    "t_input2 = test.loc[:,['Job_Clerical or administrative support']]\n",
    "t_input3 = test.loc[:,['Job_Manufacturing, construction, maintenance, or farming']]\n",
    "t_input4 = test.loc[:,['Job_Professional, managerial, or technical']]\n",
    "t_input5 = test.loc[:,['Job_Sales or service']]\n",
    "\n",
    "t_input1 = np.asarray(t_input1).astype('float32')\n",
    "t_input2 = np.asarray(t_input2).astype('float32')\n",
    "t_input3 = np.asarray(t_input3).astype('float32')\n",
    "t_input4 = np.asarray(t_input4).astype('float32')\n",
    "t_input5 = np.asarray(t_input5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49092886],\n",
       "       [0.48997596],\n",
       "       [0.49107453],\n",
       "       [0.48268172],\n",
       "       [0.48730424],\n",
       "       [0.48997596],\n",
       "       [0.4777086 ],\n",
       "       [0.49102786],\n",
       "       [0.49134395],\n",
       "       [0.49127498],\n",
       "       [0.49121407],\n",
       "       [0.49127498],\n",
       "       [0.49105105],\n",
       "       [0.49133167],\n",
       "       [0.49066594],\n",
       "       [0.49107453],\n",
       "       [0.48609582],\n",
       "       [0.4900615 ],\n",
       "       [0.49136767],\n",
       "       [0.49134395],\n",
       "       [0.49121407],\n",
       "       [0.48879763],\n",
       "       [0.49107453],\n",
       "       [0.4858593 ],\n",
       "       [0.49128994],\n",
       "       [0.4913027 ],\n",
       "       [0.48730424],\n",
       "       [0.48663548],\n",
       "       [0.4894394 ],\n",
       "       [0.4911867 ],\n",
       "       [0.48853442],\n",
       "       [0.48997596],\n",
       "       [0.4912577 ],\n",
       "       [0.49131367],\n",
       "       [0.4897448 ],\n",
       "       [0.49107453],\n",
       "       [0.49136326],\n",
       "       [0.4910241 ],\n",
       "       [0.48465696],\n",
       "       [0.49061707],\n",
       "       [0.4908177 ],\n",
       "       [0.49115488],\n",
       "       [0.48947564],\n",
       "       [0.4911867 ],\n",
       "       [0.49132302],\n",
       "       [0.4858578 ],\n",
       "       [0.49034497],\n",
       "       [0.49128994],\n",
       "       [0.49131367],\n",
       "       [0.48126373],\n",
       "       [0.48837307],\n",
       "       [0.48787907],\n",
       "       [0.49136767],\n",
       "       [0.49115488],\n",
       "       [0.48837307],\n",
       "       [0.4815168 ],\n",
       "       [0.4911867 ],\n",
       "       [0.48520717],\n",
       "       [0.47878   ],\n",
       "       [0.49111775],\n",
       "       [0.49018463],\n",
       "       [0.49133798],\n",
       "       [0.49024907],\n",
       "       [0.49034497],\n",
       "       [0.49130347],\n",
       "       [0.48053542],\n",
       "       [0.4910241 ],\n",
       "       [0.4777086 ],\n",
       "       [0.49061707],\n",
       "       [0.49133798],\n",
       "       [0.4875042 ],\n",
       "       [0.48495367],\n",
       "       [0.49017444],\n",
       "       [0.48947564],\n",
       "       [0.49111775],\n",
       "       [0.48390272],\n",
       "       [0.49113533],\n",
       "       [0.49096557],\n",
       "       [0.49017444],\n",
       "       [0.48351333],\n",
       "       [0.49133798],\n",
       "       [0.4909928 ],\n",
       "       [0.48390272],\n",
       "       [0.47549534],\n",
       "       [0.48663548],\n",
       "       [0.49134895],\n",
       "       [0.49121585],\n",
       "       [0.4908177 ],\n",
       "       [0.49061707],\n",
       "       [0.49133798],\n",
       "       [0.48609582],\n",
       "       [0.48787907],\n",
       "       [0.49133107],\n",
       "       [0.47293127],\n",
       "       [0.49132302],\n",
       "       [0.49076733],\n",
       "       [0.49034497],\n",
       "       [0.49121407],\n",
       "       [0.47961792],\n",
       "       [0.48390272],\n",
       "       [0.49096557],\n",
       "       [0.49134907],\n",
       "       [0.49121407],\n",
       "       [0.49115488],\n",
       "       [0.47549534],\n",
       "       [0.49136564],\n",
       "       [0.48997596],\n",
       "       [0.49035403],\n",
       "       [0.490725  ],\n",
       "       [0.48894092],\n",
       "       [0.49034497],\n",
       "       [0.48685518],\n",
       "       [0.49121407],\n",
       "       [0.48609582],\n",
       "       [0.48268172],\n",
       "       [0.48390272],\n",
       "       [0.4858578 ],\n",
       "       [0.48837307],\n",
       "       [0.49096557],\n",
       "       [0.48268172],\n",
       "       [0.49049136],\n",
       "       [0.49107453],\n",
       "       [0.49017444],\n",
       "       [0.48997596],\n",
       "       [0.49131367],\n",
       "       [0.4908177 ],\n",
       "       [0.49049136],\n",
       "       [0.48663548],\n",
       "       [0.48390272],\n",
       "       [0.48730424],\n",
       "       [0.49061707],\n",
       "       [0.4908972 ],\n",
       "       [0.48268172],\n",
       "       [0.47554854],\n",
       "       [0.49136183],\n",
       "       [0.49017444],\n",
       "       [0.4777086 ],\n",
       "       [0.4849452 ],\n",
       "       [0.48730424],\n",
       "       [0.48805943],\n",
       "       [0.4910777 ],\n",
       "       [0.4778668 ],\n",
       "       [0.4728197 ],\n",
       "       [0.49061707],\n",
       "       [0.49131814],\n",
       "       [0.49090204],\n",
       "       [0.4909928 ],\n",
       "       [0.48126373],\n",
       "       [0.47549534],\n",
       "       [0.48997596],\n",
       "       [0.48805943],\n",
       "       [0.48787907],\n",
       "       [0.48495367],\n",
       "       [0.48916236],\n",
       "       [0.4911867 ],\n",
       "       [0.49128994],\n",
       "       [0.490725  ],\n",
       "       [0.48837307],\n",
       "       [0.490725  ],\n",
       "       [0.49017444],\n",
       "       [0.48947564],\n",
       "       [0.49115726],\n",
       "       [0.48390272],\n",
       "       [0.48805943],\n",
       "       [0.48787907],\n",
       "       [0.48730424],\n",
       "       [0.4913344 ],\n",
       "       [0.4858578 ],\n",
       "       [0.49125907],\n",
       "       [0.4897448 ],\n",
       "       [0.49133107],\n",
       "       [0.49134395],\n",
       "       [0.49061707],\n",
       "       [0.49017444],\n",
       "       [0.48879763],\n",
       "       [0.49123755],\n",
       "       [0.48916236],\n",
       "       [0.4777086 ],\n",
       "       [0.49017444],\n",
       "       [0.48997596],\n",
       "       [0.49128994],\n",
       "       [0.47549534],\n",
       "       [0.47522599],\n",
       "       [0.49117187],\n",
       "       [0.49134395],\n",
       "       [0.49128994],\n",
       "       [0.49127498],\n",
       "       [0.47549534],\n",
       "       [0.4841664 ],\n",
       "       [0.49127498],\n",
       "       [0.49128994],\n",
       "       [0.49132302],\n",
       "       [0.48495367],\n",
       "       [0.48390272],\n",
       "       [0.49134395],\n",
       "       [0.490725  ],\n",
       "       [0.48495367],\n",
       "       [0.48730424],\n",
       "       [0.48787907],\n",
       "       [0.49111775],\n",
       "       [0.49017444],\n",
       "       [0.48997596],\n",
       "       [0.48879763],\n",
       "       [0.4913694 ],\n",
       "       [0.49128994],\n",
       "       [0.49111775],\n",
       "       [0.48730424],\n",
       "       [0.48126373],\n",
       "       [0.4910241 ],\n",
       "       [0.48879763],\n",
       "       [0.48263654],\n",
       "       [0.48495367],\n",
       "       [0.48916236],\n",
       "       [0.4777086 ],\n",
       "       [0.49017444],\n",
       "       [0.4841664 ],\n",
       "       [0.48390272],\n",
       "       [0.48664334],\n",
       "       [0.49104777],\n",
       "       [0.49132684],\n",
       "       [0.48731586],\n",
       "       [0.48685518],\n",
       "       [0.49133107],\n",
       "       [0.48663548],\n",
       "       [0.49111775],\n",
       "       [0.48997596],\n",
       "       [0.46575886],\n",
       "       [0.48663548],\n",
       "       [0.49128994],\n",
       "       [0.49136326],\n",
       "       [0.49121585],\n",
       "       [0.48495367],\n",
       "       [0.48730424],\n",
       "       [0.48663548],\n",
       "       [0.48663548],\n",
       "       [0.48520717],\n",
       "       [0.4913694 ],\n",
       "       [0.4911867 ],\n",
       "       [0.49135718],\n",
       "       [0.49134907],\n",
       "       [0.48390272],\n",
       "       [0.49104777],\n",
       "       [0.48916236],\n",
       "       [0.49121407],\n",
       "       [0.4858578 ],\n",
       "       [0.49128994],\n",
       "       [0.49127498],\n",
       "       [0.49133798],\n",
       "       [0.49049136],\n",
       "       [0.49134895],\n",
       "       [0.49034497],\n",
       "       [0.48879763],\n",
       "       [0.49115488],\n",
       "       [0.48916236],\n",
       "       [0.48268172],\n",
       "       [0.4908972 ],\n",
       "       [0.48787907],\n",
       "       [0.49034497],\n",
       "       [0.49049136],\n",
       "       [0.48916236],\n",
       "       [0.4811873 ],\n",
       "       [0.49107453],\n",
       "       [0.48663548],\n",
       "       [0.49128994],\n",
       "       [0.4913027 ],\n",
       "       [0.48947564],\n",
       "       [0.49111775],\n",
       "       [0.4858578 ],\n",
       "       [0.49096557],\n",
       "       [0.49107453],\n",
       "       [0.4909698 ],\n",
       "       [0.49096557],\n",
       "       [0.48495367],\n",
       "       [0.4911867 ],\n",
       "       [0.48916236],\n",
       "       [0.4913027 ],\n",
       "       [0.48390272],\n",
       "       [0.48495367],\n",
       "       [0.48126373],\n",
       "       [0.48663548],\n",
       "       [0.48663548],\n",
       "       [0.48837307],\n",
       "       [0.48879763],\n",
       "       [0.48916236],\n",
       "       [0.48685518],\n",
       "       [0.48730424],\n",
       "       [0.4912577 ],\n",
       "       [0.4913027 ],\n",
       "       [0.48947564],\n",
       "       [0.4858578 ],\n",
       "       [0.4858578 ],\n",
       "       [0.48916236],\n",
       "       [0.4849452 ],\n",
       "       [0.48730424],\n",
       "       [0.48787907],\n",
       "       [0.4913344 ],\n",
       "       [0.47752562],\n",
       "       [0.49112055],\n",
       "       [0.48787907]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction\n",
    "age_job_category_model.predict([t_input1, t_input2, t_input3, t_input4, t_input5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree or Pro Environment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_25 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 5)            0           ['input_21[0][0]',               \n",
      "                                                                  'input_22[0][0]',               \n",
      "                                                                  'input_23[0][0]',               \n",
      "                                                                  'input_24[0][0]',               \n",
      "                                                                  'input_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 5)            30          ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1)            6           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(1,))\n",
    "input2 = tf.keras.layers.Input(shape=(1,))\n",
    "input3 = tf.keras.layers.Input(shape=(1,))\n",
    "input4 = tf.keras.layers.Input(shape=(1,))\n",
    "input5 = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "merged = tf.keras.layers.Concatenate(axis=1)([input1, input2, input3, input4, input5])\n",
    "dense1 = tf.keras.layers.Dense(5, input_dim=1, activation=tf.keras.activations.sigmoid, use_bias=True)(merged)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.keras.activations.relu, use_bias=True)(dense1)\n",
    "degree_environment_model = tf.keras.models.Model([input1, input2, input3, input4, input5], output)\n",
    "degree_environment_model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "degree_environment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2506 - val_loss: 0.2480\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - val_loss: 0.2467\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - val_loss: 0.2495\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - val_loss: 0.2484\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2495\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - val_loss: 0.2474\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - val_loss: 0.2504\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - val_loss: 0.2473\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2487\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2477\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - val_loss: 0.2479\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - val_loss: 0.2465\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2459\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - val_loss: 0.2451\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2509 - val_loss: 0.2471\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2498 - val_loss: 0.2527\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - val_loss: 0.2483\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - val_loss: 0.2486\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2501\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2485\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - val_loss: 0.2447\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - val_loss: 0.2481\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2476\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2472\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - val_loss: 0.2494\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2455\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - val_loss: 0.2479\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2483\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2489\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - val_loss: 0.2510\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - val_loss: 0.2477\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2502 - val_loss: 0.2482\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2477\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2487\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2507 - val_loss: 0.2481\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2473\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - val_loss: 0.2491\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.2472\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2469\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2483\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2504\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2493\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2486\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.2515\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.2519\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.2502\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2458\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2492\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2506\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2495\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2486\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2495\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2468\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2496\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.2479\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.2471\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2461\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2459\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.2464\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2501\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2488\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2491\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2499\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2465\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.2501\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2500\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.2486\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2488\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.2461\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.2486\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2473\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.2498\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2467\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2506\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.2500\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.2483\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2488\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2498\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2494\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2485\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2488\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2505\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.2486\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.2500\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.2462\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.2482\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2481\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.2487\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.2477\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2459\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2472\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2487\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2492\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2482\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2505 - val_loss: 0.2471\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2445\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2474\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2504 - val_loss: 0.2488\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2488\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x290b7c5b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Data\n",
    "input1 = train.loc[:,['age']]\n",
    "input2 = train.loc[:,['Workload_increased']]\n",
    "input3 = train.loc[:,['Workload_decreased']]\n",
    "input4 = train.loc[:,['Gradutae_degree']]\n",
    "input5 = train.loc[:,['ProEnvironment']]\n",
    "\n",
    "input1 = np.asarray(input1).astype('float32')\n",
    "input2 = np.asarray(input2).astype('float32')\n",
    "input3 = np.asarray(input3).astype('float32')\n",
    "input4 = np.asarray(input4).astype('float32')\n",
    "input5 = np.asarray(input5).astype('float32')\n",
    "\n",
    "y = train.loc[:,['wfh_expect']]\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "# Validation Data\n",
    "v_input1 = validation.loc[:,['age']]\n",
    "v_input2 = validation.loc[:,['Workload_increased']]\n",
    "v_input3 = validation.loc[:,['Workload_decreased']]\n",
    "v_input4 = validation.loc[:,['Gradutae_degree']]\n",
    "v_input5 = validation.loc[:,['ProEnvironment']]\n",
    "\n",
    "v_input1 = np.asarray(v_input1).astype('float32')\n",
    "v_input2 = np.asarray(v_input2).astype('float32')\n",
    "v_input3 = np.asarray(v_input3).astype('float32')\n",
    "v_input4 = np.asarray(v_input4).astype('float32')\n",
    "v_input5 = np.asarray(v_input5).astype('float32')\n",
    "\n",
    "v_y = validation.loc[:,['wfh_expect']]\n",
    "v_y = np.asarray(v_y).astype('float32')\n",
    "\n",
    "degree_environment_model.fit([input1, input2, input3, input4, input5],y, batch_size=36, epochs=100, \n",
    "                        validation_data=([v_input1, v_input2, v_input3, v_input4, v_input5], v_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "t_input1 = test.loc[:,['age']]\n",
    "t_input2 = test.loc[:,['Workload_increased']]\n",
    "t_input3 = test.loc[:,['Workload_decreased']]\n",
    "t_input4 = test.loc[:,['Gradutae_degree']]\n",
    "t_input5 = test.loc[:,['ProEnvironment']]\n",
    "\n",
    "t_input1 = np.asarray(t_input1).astype('float32')\n",
    "t_input2 = np.asarray(t_input2).astype('float32')\n",
    "t_input3 = np.asarray(t_input3).astype('float32')\n",
    "t_input4 = np.asarray(t_input4).astype('float32')\n",
    "t_input5 = np.asarray(t_input5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 628us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48788524],\n",
       "       [0.487656  ],\n",
       "       [0.4879204 ],\n",
       "       [0.48520166],\n",
       "       [0.48683208],\n",
       "       [0.487656  ],\n",
       "       [0.48335648],\n",
       "       [0.48789835],\n",
       "       [0.48796362],\n",
       "       [0.48795462],\n",
       "       [0.4879452 ],\n",
       "       [0.48795462],\n",
       "       [0.48795402],\n",
       "       [0.4879613 ],\n",
       "       [0.48782486],\n",
       "       [0.4879204 ],\n",
       "       [0.48660904],\n",
       "       [0.48767382],\n",
       "       [0.48796582],\n",
       "       [0.48796362],\n",
       "       [0.4879452 ],\n",
       "       [0.48731196],\n",
       "       [0.4879204 ],\n",
       "       [0.48579633],\n",
       "       [0.48795676],\n",
       "       [0.48795855],\n",
       "       [0.48683208],\n",
       "       [0.48660684],\n",
       "       [0.48740232],\n",
       "       [0.48794067],\n",
       "       [0.48726445],\n",
       "       [0.487656  ],\n",
       "       [0.4879521 ],\n",
       "       [0.48795992],\n",
       "       [0.48759186],\n",
       "       [0.4879204 ],\n",
       "       [0.48796546],\n",
       "       [0.4879105 ],\n",
       "       [0.4857415 ],\n",
       "       [0.48782074],\n",
       "       [0.487867  ],\n",
       "       [0.48793507],\n",
       "       [0.48751497],\n",
       "       [0.48794067],\n",
       "       [0.48796117],\n",
       "       [0.48633897],\n",
       "       [0.4877534 ],\n",
       "       [0.48795676],\n",
       "       [0.48795992],\n",
       "       [0.48468006],\n",
       "       [0.4871794 ],\n",
       "       [0.4870211 ],\n",
       "       [0.48796582],\n",
       "       [0.48793507],\n",
       "       [0.4871794 ],\n",
       "       [0.48549992],\n",
       "       [0.48794067],\n",
       "       [0.48637903],\n",
       "       [0.48829263],\n",
       "       [0.4879284 ],\n",
       "       [0.4876445 ],\n",
       "       [0.4879629 ],\n",
       "       [0.48772192],\n",
       "       [0.4877534 ],\n",
       "       [0.48795694],\n",
       "       [0.4881299 ],\n",
       "       [0.4879105 ],\n",
       "       [0.48335648],\n",
       "       [0.48782074],\n",
       "       [0.4879629 ],\n",
       "       [0.48698455],\n",
       "       [0.48602128],\n",
       "       [0.48770922],\n",
       "       [0.48751497],\n",
       "       [0.4879284 ],\n",
       "       [0.4856453 ],\n",
       "       [0.48792815],\n",
       "       [0.4878986 ],\n",
       "       [0.48770922],\n",
       "       [0.48535657],\n",
       "       [0.4879629 ],\n",
       "       [0.48789912],\n",
       "       [0.4856453 ],\n",
       "       [0.48253024],\n",
       "       [0.48660684],\n",
       "       [0.4879632 ],\n",
       "       [0.4879409 ],\n",
       "       [0.487867  ],\n",
       "       [0.48782074],\n",
       "       [0.4879629 ],\n",
       "       [0.48660904],\n",
       "       [0.4870211 ],\n",
       "       [0.48796213],\n",
       "       [0.48157817],\n",
       "       [0.48796117],\n",
       "       [0.48784876],\n",
       "       [0.4877534 ],\n",
       "       [0.4879452 ],\n",
       "       [0.48406905],\n",
       "       [0.4856453 ],\n",
       "       [0.4878986 ],\n",
       "       [0.48796415],\n",
       "       [0.4879452 ],\n",
       "       [0.48793507],\n",
       "       [0.48253024],\n",
       "       [0.48796564],\n",
       "       [0.487656  ],\n",
       "       [0.48770106],\n",
       "       [0.48784602],\n",
       "       [0.48737496],\n",
       "       [0.4877534 ],\n",
       "       [0.4868101 ],\n",
       "       [0.4879452 ],\n",
       "       [0.48660904],\n",
       "       [0.48520166],\n",
       "       [0.4856453 ],\n",
       "       [0.48633897],\n",
       "       [0.4871794 ],\n",
       "       [0.4878986 ],\n",
       "       [0.48520166],\n",
       "       [0.48779023],\n",
       "       [0.4879204 ],\n",
       "       [0.48770922],\n",
       "       [0.487656  ],\n",
       "       [0.48795992],\n",
       "       [0.487867  ],\n",
       "       [0.48779023],\n",
       "       [0.48660684],\n",
       "       [0.4856453 ],\n",
       "       [0.48683208],\n",
       "       [0.48782074],\n",
       "       [0.48788428],\n",
       "       [0.48520166],\n",
       "       [0.48437595],\n",
       "       [0.48796523],\n",
       "       [0.48770922],\n",
       "       [0.48335648],\n",
       "       [0.48534822],\n",
       "       [0.48683208],\n",
       "       [0.48713517],\n",
       "       [0.4879104 ],\n",
       "       [0.48476732],\n",
       "       [0.48398876],\n",
       "       [0.48782074],\n",
       "       [0.48795974],\n",
       "       [0.4878658 ],\n",
       "       [0.48789912],\n",
       "       [0.48468006],\n",
       "       [0.48253024],\n",
       "       [0.487656  ],\n",
       "       [0.48713517],\n",
       "       [0.4870211 ],\n",
       "       [0.48602128],\n",
       "       [0.4874226 ],\n",
       "       [0.48794067],\n",
       "       [0.48795676],\n",
       "       [0.48784602],\n",
       "       [0.4871794 ],\n",
       "       [0.48784602],\n",
       "       [0.48770922],\n",
       "       [0.48751497],\n",
       "       [0.48792863],\n",
       "       [0.4856453 ],\n",
       "       [0.48713517],\n",
       "       [0.4870211 ],\n",
       "       [0.48683208],\n",
       "       [0.48796195],\n",
       "       [0.48633897],\n",
       "       [0.4879492 ],\n",
       "       [0.48759186],\n",
       "       [0.48796213],\n",
       "       [0.48796362],\n",
       "       [0.48782074],\n",
       "       [0.48770922],\n",
       "       [0.48731196],\n",
       "       [0.487949  ],\n",
       "       [0.4874226 ],\n",
       "       [0.48335648],\n",
       "       [0.48770922],\n",
       "       [0.487656  ],\n",
       "       [0.48795676],\n",
       "       [0.48253024],\n",
       "       [0.4800644 ],\n",
       "       [0.48795915],\n",
       "       [0.48796362],\n",
       "       [0.48795676],\n",
       "       [0.48795462],\n",
       "       [0.48253024],\n",
       "       [0.48611802],\n",
       "       [0.48795462],\n",
       "       [0.48795676],\n",
       "       [0.48796117],\n",
       "       [0.48602128],\n",
       "       [0.4856453 ],\n",
       "       [0.48796362],\n",
       "       [0.48784602],\n",
       "       [0.48602128],\n",
       "       [0.48683208],\n",
       "       [0.4870211 ],\n",
       "       [0.4879284 ],\n",
       "       [0.48770922],\n",
       "       [0.487656  ],\n",
       "       [0.48731196],\n",
       "       [0.487966  ],\n",
       "       [0.48795676],\n",
       "       [0.4879284 ],\n",
       "       [0.48683208],\n",
       "       [0.48468006],\n",
       "       [0.4879105 ],\n",
       "       [0.48731196],\n",
       "       [0.4841652 ],\n",
       "       [0.48602128],\n",
       "       [0.4874226 ],\n",
       "       [0.48335648],\n",
       "       [0.48770922],\n",
       "       [0.48611802],\n",
       "       [0.4856453 ],\n",
       "       [0.48616904],\n",
       "       [0.48791063],\n",
       "       [0.48796093],\n",
       "       [0.4864787 ],\n",
       "       [0.4868101 ],\n",
       "       [0.48796213],\n",
       "       [0.48660684],\n",
       "       [0.4879284 ],\n",
       "       [0.487656  ],\n",
       "       [0.47453487],\n",
       "       [0.48660684],\n",
       "       [0.48795676],\n",
       "       [0.48796546],\n",
       "       [0.4879409 ],\n",
       "       [0.48602128],\n",
       "       [0.48683208],\n",
       "       [0.48660684],\n",
       "       [0.48660684],\n",
       "       [0.48637903],\n",
       "       [0.487966  ],\n",
       "       [0.48794067],\n",
       "       [0.487965  ],\n",
       "       [0.48796415],\n",
       "       [0.4856453 ],\n",
       "       [0.48791063],\n",
       "       [0.4874226 ],\n",
       "       [0.4879452 ],\n",
       "       [0.48633897],\n",
       "       [0.48795676],\n",
       "       [0.48795462],\n",
       "       [0.4879629 ],\n",
       "       [0.48779023],\n",
       "       [0.4879632 ],\n",
       "       [0.4877534 ],\n",
       "       [0.48731196],\n",
       "       [0.48793507],\n",
       "       [0.4874226 ],\n",
       "       [0.48520166],\n",
       "       [0.48788428],\n",
       "       [0.4870211 ],\n",
       "       [0.4877534 ],\n",
       "       [0.48779023],\n",
       "       [0.4874226 ],\n",
       "       [0.4833932 ],\n",
       "       [0.4879204 ],\n",
       "       [0.48660684],\n",
       "       [0.48795676],\n",
       "       [0.48795855],\n",
       "       [0.48751497],\n",
       "       [0.4879284 ],\n",
       "       [0.48633897],\n",
       "       [0.4878986 ],\n",
       "       [0.4879204 ],\n",
       "       [0.48788363],\n",
       "       [0.4878986 ],\n",
       "       [0.48602128],\n",
       "       [0.48794067],\n",
       "       [0.4874226 ],\n",
       "       [0.48795855],\n",
       "       [0.4856453 ],\n",
       "       [0.48602128],\n",
       "       [0.48468006],\n",
       "       [0.48660684],\n",
       "       [0.48660684],\n",
       "       [0.4871794 ],\n",
       "       [0.48731196],\n",
       "       [0.4874226 ],\n",
       "       [0.4868101 ],\n",
       "       [0.48683208],\n",
       "       [0.4879521 ],\n",
       "       [0.48795855],\n",
       "       [0.48751497],\n",
       "       [0.48633897],\n",
       "       [0.48633897],\n",
       "       [0.4874226 ],\n",
       "       [0.48534822],\n",
       "       [0.48683208],\n",
       "       [0.4870211 ],\n",
       "       [0.48796195],\n",
       "       [0.4813714 ],\n",
       "       [0.4879204 ],\n",
       "       [0.4870211 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction\n",
    "degree_environment_model.predict([t_input1, t_input2, t_input3, t_input4, t_input5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
